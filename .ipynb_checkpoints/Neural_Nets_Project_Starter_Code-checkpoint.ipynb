{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (2.9.0)\n",
      "Requirement already satisfied: numpy in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (from imageio) (1.19.5)\n",
      "Requirement already satisfied: pillow in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (from imageio) (8.3.1)\n",
      "Requirement already satisfied: scikit-image in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (0.18.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (from scikit-image) (1.19.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (from scikit-image) (2021.10.12)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (from scikit-image) (8.3.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (from scikit-image) (1.7.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (from scikit-image) (3.4.2)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (from scikit-image) (2.6.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: six in /home/ajaxgen/anaconda3/envs/msmlai/lib/python3.9/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# Install imageio for imread as imread from scipy.misc is deprecated\n",
    "\n",
    "!pip install imageio\n",
    "#!pip install opencv-python\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# following in deprecated:\n",
    "# from scipy.misc import imread, imresize\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-22 21:51:23.707265: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /snap/alacritty/46/usr/lib/x86_64-linux-gnu:/snap/alacritty/46/lib/x86_64-linux-gnu:/snap/alacritty/46/usr/lib/x86_64-linux-gnu/dri\n",
      "2021-10-22 21:51:23.707290: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# set_random_seed is deprecated.\n",
    "# tf.set_random_seed(30)\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_doc = np.random.permutation(open('/notebooks/storage/Final_data/Collated_training/train.csv').readlines())\n",
    "# val_doc = np.random.permutation(open('/notebooks/storage/Final_data/Collated_training/val.csv').readlines())\n",
    "\n",
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "\n",
    "#hyperparameters\n",
    "batch_size = 64 #experiment with the batch size\n",
    "image_height = 160\n",
    "image_width = 160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = np.round(np.linspace(0, 29, 30)).astype(int) #list of image numbers for video.\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        if len(t) % batch_size == 0: # if divisible by batch_size\n",
    "            num_batches = int(len(t)/batch_size)\n",
    "            last_batch_size = 0\n",
    "        else:  #if not divisible by batch_size\n",
    "            num_batches = len(t) // batch_size\n",
    "            last_batch_size = len(t) % batch_size #surplus in the last batch\n",
    "        \n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,len(img_idx),image_height,image_width,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    resized_image = resize(image,(image_height,image_width))\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (resized_image[:,:,0])/255\n",
    "                    batch_data[folder,idx,:,:,1] = (resized_image[:,:,1])/255\n",
    "                    batch_data[folder,idx,:,:,2] = (resized_image[:,:,2])/255\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        if len(t) % batch_size != 0: # if not divisible by batch_size\n",
    "            batch_data = np.zeros((last_batch_size,len(img_idx),image_height,image_width,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((last_batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(last_batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*last_batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*last_batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    resized_image = resize(image,(image_height,image_width))\n",
    "\n",
    "                    batch_data[folder,idx,:,:,0] = (resized_image[:,:,0])/255\n",
    "                    batch_data[folder,idx,:,:,1] = (resized_image[:,:,1])/255\n",
    "                    batch_data[folder,idx,:,:,2] = (resized_image[:,:,2])/255\n",
    "\n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "# train_path = '/notebooks/storage/Final_data/Collated_training/train'\n",
    "# val_path = '/notebooks/storage/Final_data/Collated_training/val'\n",
    "train_path = 'Project_data/train'\n",
    "val_path = 'Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 20# choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - Conv3D\n",
    "## Batch size = 64, No. of Epochs  = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-22 21:51:24.662424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 21:51:24.663362: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /snap/alacritty/46/usr/lib/x86_64-linux-gnu:/snap/alacritty/46/lib/x86_64-linux-gnu:/snap/alacritty/46/usr/lib/x86_64-linux-gnu/dri\n",
      "2021-10-22 21:51:24.663476: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /snap/alacritty/46/usr/lib/x86_64-linux-gnu:/snap/alacritty/46/lib/x86_64-linux-gnu:/snap/alacritty/46/usr/lib/x86_64-linux-gnu/dri\n",
      "2021-10-22 21:51:24.663570: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /snap/alacritty/46/usr/lib/x86_64-linux-gnu:/snap/alacritty/46/lib/x86_64-linux-gnu:/snap/alacritty/46/usr/lib/x86_64-linux-gnu/dri\n",
      "2021-10-22 21:51:24.663658: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /snap/alacritty/46/usr/lib/x86_64-linux-gnu:/snap/alacritty/46/lib/x86_64-linux-gnu:/snap/alacritty/46/usr/lib/x86_64-linux-gnu/dri\n",
      "2021-10-22 21:51:24.663747: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /snap/alacritty/46/usr/lib/x86_64-linux-gnu:/snap/alacritty/46/lib/x86_64-linux-gnu:/snap/alacritty/46/usr/lib/x86_64-linux-gnu/dri\n",
      "2021-10-22 21:51:24.663836: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /snap/alacritty/46/usr/lib/x86_64-linux-gnu:/snap/alacritty/46/lib/x86_64-linux-gnu:/snap/alacritty/46/usr/lib/x86_64-linux-gnu/dri\n",
      "2021-10-22 21:51:24.663924: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /snap/alacritty/46/usr/lib/x86_64-linux-gnu:/snap/alacritty/46/lib/x86_64-linux-gnu:/snap/alacritty/46/usr/lib/x86_64-linux-gnu/dri\n",
      "2021-10-22 21:51:24.664014: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /snap/alacritty/46/usr/lib/x86_64-linux-gnu:/snap/alacritty/46/lib/x86_64-linux-gnu:/snap/alacritty/46/usr/lib/x86_64-linux-gnu/dri\n",
      "2021-10-22 21:51:24.664031: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-10-22 21:51:24.665024: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Conv3D model\n",
    "model = Sequential()\n",
    "model.add(Conv3D(16, (3,3,3), # filters, kernel size\n",
    "                 padding = 'same', \n",
    "                 input_shape = (30,160,160,3))) #frames to sample, height, weight, channels\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 30, 160, 160, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 30, 160, 160, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 160, 160, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 15, 80, 80, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 15, 80, 80, 32)    4128      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 15, 80, 80, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 15, 80, 80, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 7, 40, 40, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 7, 40, 40, 64)     16448     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 40, 40, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 40, 40, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 3, 20, 20, 64)     0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 76800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4915264   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 4,942,597\n",
      "Trainable params: 4,942,117\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def compile_and_summarize(learning_rate = 0.01): \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    print (model.summary())\n",
    "\n",
    "compile_and_summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model checkpoints\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "def model_checkpoints(model_prefix = 'model_init'):\n",
    "    print('Initializing model checkpoints')\n",
    "    model_name = model_prefix + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "\n",
    "    if not os.path.exists(model_name):\n",
    "        os.mkdir(model_name)\n",
    "\n",
    "    filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "    #reduce learning rate when val_loss has stopped improving.\n",
    "    #monitor -> metric to monitor\n",
    "    #verbose -> prints message to stdout\n",
    "    #patience -> number of epochs with no imporvement after which learning rate is reduced\n",
    "    #factor -> factor by which learning rate is reduced.\n",
    "    LR = ReduceLROnPlateau(monitor='val_loss', factor= 0.2, verbose=1,patience=5)\n",
    "    callbacks_list = [checkpoint, LR]\n",
    "    return callbacks_list\n",
    "\n",
    "callbacks_list = model_checkpoints()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating steps per epoch and validation steps\n"
     ]
    }
   ],
   "source": [
    "def calc_steps_per_epoch(btch_size=64):\n",
    "    print('Calculating steps per epoch and validation steps')\n",
    "    if (num_train_sequences%btch_size) == 0:\n",
    "        steps_per_epoch = int(num_train_sequences/btch_size)\n",
    "    else:\n",
    "        steps_per_epoch = (num_train_sequences//btch_size) + 1\n",
    "    return steps_per_epoch\n",
    "\n",
    "def calc_validation_steps(btch_size=64):\n",
    "    if (num_val_sequences%btch_size) == 0:\n",
    "        validation_steps = int(num_val_sequences/btch_size)\n",
    "    else:\n",
    "        validation_steps = (num_val_sequences//btch_size) + 1\n",
    "    return validation_steps\n",
    "\n",
    "steps_per_epoch = calc_steps_per_epoch(batch_size)\n",
    "validation_steps = calc_validation_steps(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Uncomment below two cells to train and see the graph</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_loss_plot(history):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "    axes[0].plot(history.history['loss'])   \n",
    "    axes[0].plot(history.history['val_loss'])\n",
    "    axes[0].legend(['loss','val_loss'])\n",
    "\n",
    "    axes[1].plot(history.history['categorical_accuracy'])   \n",
    "    axes[1].plot(history.history['val_categorical_accuracy'])\n",
    "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])\n",
    "\n",
    "# train_val_loss_plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    The above graph shows this model to be overfitted as the training loss is low while the validation loss is high. Accuracy is also not as high as expected. We can try with a more complex model to increase the training accuracy and change the dropout to reduce overfitting.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv3D model2\n",
    "model = Sequential()\n",
    "model.add(Conv3D(16, (3,3,3), # filters, kernel size\n",
    "                 padding = 'same', \n",
    "                 input_shape = (30,160,160,3))) #frames to sample, height, weight, channels\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(32, (2,2,2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(128, (2,2,2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(256, (2,2,2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(5,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_3 (Conv3D)            (None, 30, 160, 160, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 30, 160, 160, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 30, 160, 160, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 15, 80, 80, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 15, 80, 80, 32)    4128      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 15, 80, 80, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 15, 80, 80, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 7, 40, 40, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 7, 40, 40, 128)    32896     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 7, 40, 40, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 7, 40, 40, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 3, 20, 20, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 3, 20, 20, 256)    262400    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 3, 20, 20, 256)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 3, 20, 20, 256)    1024      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 1, 10, 10, 256)    0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               3276928   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,597,573\n",
      "Trainable params: 3,596,197\n",
      "Non-trainable params: 1,376\n",
      "_________________________________________________________________\n",
      "None\n",
      "Initializing model checkpoints\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Calculating steps per epoch and validation steps\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "\n",
    "compile_and_summarize()\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "\n",
    "callbacks_list = model_checkpoints('model_init2')\n",
    "\n",
    "steps_per_epoch = calc_steps_per_epoch(batch_size)\n",
    "validation_steps = calc_validation_steps(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Uncomment below two cells to train and see the graph</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history2 = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_val_loss_plot(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    This model also overfits. There is some improvement in the training accuracy.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3\n",
    "## Learning rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv3D model3\n",
    "model = Sequential()\n",
    "model.add(Conv3D(16, (3,3,3), # filters, kernel size\n",
    "                 padding = 'same', \n",
    "                 input_shape = (30,160,160,3))) #frames to sample, height, weight, channels\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(32, (2,2,2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(64, (2,2,2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(128, (2,2,2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(5,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_7 (Conv3D)            (None, 30, 160, 160, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 30, 160, 160, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 30, 160, 160, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 15, 80, 80, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 15, 80, 80, 32)    4128      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15, 80, 80, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 15, 80, 80, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 7, 40, 40, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 7, 40, 40, 64)     16448     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 7, 40, 40, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 7, 40, 40, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 3, 20, 20, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 3, 20, 20, 128)    65664     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 3, 20, 20, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 3, 20, 20, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 1, 10, 10, 128)    0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                819264    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 912,773\n",
      "Trainable params: 912,037\n",
      "Non-trainable params: 736\n",
      "_________________________________________________________________\n",
      "None\n",
      "Initializing model checkpoints\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Calculating steps per epoch and validation steps\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "\n",
    "compile_and_summarize(0.0001)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "\n",
    "callbacks_list = model_checkpoints('model_init3')\n",
    "\n",
    "steps_per_epoch = calc_steps_per_epoch(batch_size)\n",
    "validation_steps = calc_validation_steps(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Uncomment below two cells to train and see the graph</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history3 = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_val_loss_plot(history3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='blue'> The model is still performing badly on the validation set. The training accuracy is also not high.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv3D model4\n",
    "model = Sequential()\n",
    "model.add(Conv3D(16, (3,3,3), # filters, kernel size\n",
    "                 padding = 'same', \n",
    "                 input_shape = (30,160,160,3))) #frames to sample, height, weight, channels\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(32, (2,2,2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(64, (2,2,2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(128, (2,2,2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv3D(256, (2,2,2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Dense(5,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_11 (Conv3D)           (None, 30, 160, 160, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 30, 160, 160, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 30, 160, 160, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 15, 80, 80, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 15, 80, 80, 32)    4128      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 15, 80, 80, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 15, 80, 80, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_12 (MaxPooling (None, 7, 40, 40, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 7, 40, 40, 64)     16448     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 7, 40, 40, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 7, 40, 40, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_13 (MaxPooling (None, 3, 20, 20, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 3, 20, 20, 128)    65664     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 3, 20, 20, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 3, 20, 20, 128)    512       \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 3, 20, 20, 256)    262400    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 3, 20, 20, 256)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 3, 20, 20, 256)    1024      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling (None, 1, 10, 10, 256)    0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               3276928   \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,647,045\n",
      "Trainable params: 3,645,541\n",
      "Non-trainable params: 1,504\n",
      "_________________________________________________________________\n",
      "None\n",
      "Initializing model checkpoints\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Calculating steps per epoch and validation steps\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "num_epochs=30\n",
    "\n",
    "compile_and_summarize(0.0002)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "\n",
    "callbacks_list = model_checkpoints('model_init4')\n",
    "\n",
    "steps_per_epoch = calc_steps_per_epoch(batch_size)\n",
    "validation_steps = calc_validation_steps(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Uncomment below two cells to train and see the graph</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history4 = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_val_loss_plot(history4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> The model still overfits, but the accuracy has imporved a little - 71% for train and 58% for validation.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5\n",
    "### CNN + GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.recurrent import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN + GRU model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
    "                          input_shape=(30,160,160,3)))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(256, (3, 3) , padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 30, 160, 160, 16)  448       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 30, 160, 160, 16)  64        \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 80, 80, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 30, 80, 80, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 80, 80, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 30, 40, 40, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 30, 40, 40, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 30, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 30, 20, 20, 128)   73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 30, 20, 20, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 30, 10, 10, 128)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 30, 10, 10, 256)   295168    \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 30, 10, 10, 256)   1024      \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 30, 5, 5, 256)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 30, 6400)          0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 128)               2507136   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 2,918,885\n",
      "Trainable params: 2,917,893\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n",
      "None\n",
      "Initializing model checkpoints\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Calculating steps per epoch and validation steps\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "num_epochs=20\n",
    "\n",
    "compile_and_summarize(0.0002)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "\n",
    "callbacks_list = model_checkpoints('model_init5')\n",
    "\n",
    "steps_per_epoch = calc_steps_per_epoch(batch_size)\n",
    "validation_steps = calc_validation_steps(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history5 = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_val_loss_plot(history5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> CNN with GRU(RNN) also overfits.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + GRU : Adding more dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN + GRU model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
    "                          input_shape=(30,image_height,image_width,3)))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(256, (3, 3) , padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_16 (TimeDis (None, 30, 160, 160, 16)  448       \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 30, 160, 160, 16)  64        \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 30, 80, 80, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 30, 80, 80, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 30, 80, 80, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 30, 80, 80, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_21 (TimeDis (None, 30, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 30, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_22 (TimeDis (None, 30, 40, 40, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 30, 40, 40, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 30, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 30, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_25 (TimeDis (None, 30, 20, 20, 128)   73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_26 (TimeDis (None, 30, 20, 20, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 30, 10, 10, 128)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 30, 10, 10, 256)   295168    \n",
      "_________________________________________________________________\n",
      "time_distributed_29 (TimeDis (None, 30, 10, 10, 256)   1024      \n",
      "_________________________________________________________________\n",
      "time_distributed_30 (TimeDis (None, 30, 5, 5, 256)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_31 (TimeDis (None, 30, 6400)          0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               2507136   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 2,918,885\n",
      "Trainable params: 2,917,893\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n",
      "None\n",
      "Initializing model checkpoints\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Calculating steps per epoch and validation steps\n"
     ]
    }
   ],
   "source": [
    "batch_size=20\n",
    "num_epochs=40\n",
    "\n",
    "compile_and_summarize(0.0002)\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n",
    "\n",
    "callbacks_list = model_checkpoints('model_init6')\n",
    "\n",
    "steps_per_epoch = calc_steps_per_epoch(batch_size)\n",
    "validation_steps = calc_validation_steps(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/train ; batch size = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-22 21:51:29.153957: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.9697 - categorical_accuracy: 0.2247Source path =  Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 254s 7s/step - loss: 1.9697 - categorical_accuracy: 0.2247 - val_loss: 1.6912 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: saving model to model_init6_2021-10-2221_51_24.592945/model-00001-1.96969-0.22474-1.69121-0.21000.h5\n",
      "Epoch 2/40\n",
      "34/34 [==============================] - 260s 8s/step - loss: 1.8106 - categorical_accuracy: 0.2685 - val_loss: 1.8913 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00002: saving model to model_init6_2021-10-2221_51_24.592945/model-00002-1.81062-0.26848-1.89130-0.19000.h5\n",
      "Epoch 3/40\n",
      "34/34 [==============================] - 264s 8s/step - loss: 1.6470 - categorical_accuracy: 0.3303 - val_loss: 1.8761 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00003: saving model to model_init6_2021-10-2221_51_24.592945/model-00003-1.64699-0.33032-1.87609-0.25000.h5\n",
      "Epoch 4/40\n",
      "34/34 [==============================] - 259s 8s/step - loss: 1.5958 - categorical_accuracy: 0.3243 - val_loss: 2.0993 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00004: saving model to model_init6_2021-10-2221_51_24.592945/model-00004-1.59581-0.32428-2.09928-0.21000.h5\n",
      "Epoch 5/40\n",
      "34/34 [==============================] - 260s 8s/step - loss: 1.6000 - categorical_accuracy: 0.3394 - val_loss: 2.2468 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00005: saving model to model_init6_2021-10-2221_51_24.592945/model-00005-1.60004-0.33937-2.24682-0.19000.h5\n",
      "Epoch 6/40\n",
      "34/34 [==============================] - 260s 8s/step - loss: 1.5558 - categorical_accuracy: 0.3514 - val_loss: 2.2011 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00006: saving model to model_init6_2021-10-2221_51_24.592945/model-00006-1.55578-0.35143-2.20115-0.19000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n",
      "Epoch 7/40\n",
      "34/34 [==============================] - 261s 8s/step - loss: 1.4888 - categorical_accuracy: 0.3560 - val_loss: 2.2638 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00007: saving model to model_init6_2021-10-2221_51_24.592945/model-00007-1.48884-0.35596-2.26385-0.15000.h5\n",
      "Epoch 8/40\n",
      "34/34 [==============================] - 261s 8s/step - loss: 1.4148 - categorical_accuracy: 0.3891 - val_loss: 2.3255 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00008: saving model to model_init6_2021-10-2221_51_24.592945/model-00008-1.41484-0.38914-2.32553-0.22000.h5\n",
      "Epoch 9/40\n",
      "34/34 [==============================] - 261s 8s/step - loss: 1.4056 - categorical_accuracy: 0.4193 - val_loss: 2.1351 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00009: saving model to model_init6_2021-10-2221_51_24.592945/model-00009-1.40556-0.41931-2.13508-0.20000.h5\n",
      "Epoch 10/40\n",
      "34/34 [==============================] - 263s 8s/step - loss: 1.4014 - categorical_accuracy: 0.4087 - val_loss: 2.5404 - val_categorical_accuracy: 0.1100\n",
      "\n",
      "Epoch 00010: saving model to model_init6_2021-10-2221_51_24.592945/model-00010-1.40144-0.40875-2.54043-0.11000.h5\n",
      "Epoch 11/40\n",
      "34/34 [==============================] - 264s 8s/step - loss: 1.3633 - categorical_accuracy: 0.4344 - val_loss: 2.3144 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00011: saving model to model_init6_2021-10-2221_51_24.592945/model-00011-1.36335-0.43439-2.31440-0.18000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n",
      "Epoch 12/40\n",
      "34/34 [==============================] - 265s 8s/step - loss: 1.3080 - categorical_accuracy: 0.4615 - val_loss: 2.3226 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00012: saving model to model_init6_2021-10-2221_51_24.592945/model-00012-1.30798-0.46154-2.32264-0.21000.h5\n",
      "Epoch 13/40\n",
      "34/34 [==============================] - 264s 8s/step - loss: 1.2939 - categorical_accuracy: 0.4555 - val_loss: 2.3631 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00013: saving model to model_init6_2021-10-2221_51_24.592945/model-00013-1.29395-0.45551-2.36312-0.18000.h5\n",
      "Epoch 14/40\n",
      "34/34 [==============================] - 265s 8s/step - loss: 1.3501 - categorical_accuracy: 0.4359 - val_loss: 2.2490 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00014: saving model to model_init6_2021-10-2221_51_24.592945/model-00014-1.35012-0.43590-2.24895-0.26000.h5\n",
      "Epoch 15/40\n",
      "34/34 [==============================] - 264s 8s/step - loss: 1.3259 - categorical_accuracy: 0.4585 - val_loss: 2.3511 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00015: saving model to model_init6_2021-10-2221_51_24.592945/model-00015-1.32586-0.45852-2.35109-0.21000.h5\n",
      "Epoch 16/40\n",
      "34/34 [==============================] - 268s 8s/step - loss: 1.3028 - categorical_accuracy: 0.4510 - val_loss: 2.2125 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00016: saving model to model_init6_2021-10-2221_51_24.592945/model-00016-1.30277-0.45098-2.21248-0.21000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.5999999959603884e-06.\n",
      "Epoch 17/40\n",
      "34/34 [==============================] - 267s 8s/step - loss: 1.2779 - categorical_accuracy: 0.4480 - val_loss: 2.2402 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00017: saving model to model_init6_2021-10-2221_51_24.592945/model-00017-1.27794-0.44796-2.24016-0.21000.h5\n",
      "Epoch 18/40\n",
      "34/34 [==============================] - 268s 8s/step - loss: 1.2809 - categorical_accuracy: 0.4389 - val_loss: 2.1483 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00018: saving model to model_init6_2021-10-2221_51_24.592945/model-00018-1.28092-0.43891-2.14832-0.20000.h5\n",
      "Epoch 19/40\n",
      "34/34 [==============================] - 269s 8s/step - loss: 1.3223 - categorical_accuracy: 0.4525 - val_loss: 2.2665 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00019: saving model to model_init6_2021-10-2221_51_24.592945/model-00019-1.32232-0.45249-2.26653-0.16000.h5\n",
      "Epoch 20/40\n",
      "34/34 [==============================] - 269s 8s/step - loss: 1.3115 - categorical_accuracy: 0.4434 - val_loss: 2.0182 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00020: saving model to model_init6_2021-10-2221_51_24.592945/model-00020-1.31153-0.44344-2.01823-0.27000.h5\n",
      "Epoch 21/40\n",
      "34/34 [==============================] - 270s 8s/step - loss: 1.3273 - categorical_accuracy: 0.4419 - val_loss: 2.1270 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00021: saving model to model_init6_2021-10-2221_51_24.592945/model-00021-1.32733-0.44193-2.12703-0.21000.h5\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.200000037395512e-07.\n",
      "Epoch 22/40\n",
      "34/34 [==============================] - 269s 8s/step - loss: 1.3169 - categorical_accuracy: 0.4208 - val_loss: 2.1856 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00022: saving model to model_init6_2021-10-2221_51_24.592945/model-00022-1.31687-0.42081-2.18559-0.18000.h5\n",
      "Epoch 23/40\n",
      "34/34 [==============================] - 271s 8s/step - loss: 1.3491 - categorical_accuracy: 0.3906 - val_loss: 2.1579 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00023: saving model to model_init6_2021-10-2221_51_24.592945/model-00023-1.34915-0.39065-2.15788-0.20000.h5\n",
      "Epoch 24/40\n",
      "34/34 [==============================] - 274s 8s/step - loss: 1.3070 - categorical_accuracy: 0.4465 - val_loss: 2.1367 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00024: saving model to model_init6_2021-10-2221_51_24.592945/model-00024-1.30702-0.44646-2.13667-0.20000.h5\n",
      "Epoch 25/40\n",
      "34/34 [==============================] - 274s 8s/step - loss: 1.3337 - categorical_accuracy: 0.4329 - val_loss: 2.0525 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00025: saving model to model_init6_2021-10-2221_51_24.592945/model-00025-1.33373-0.43288-2.05251-0.23000.h5\n",
      "Epoch 26/40\n",
      "34/34 [==============================] - 274s 8s/step - loss: 1.3037 - categorical_accuracy: 0.4615 - val_loss: 2.1030 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00026: saving model to model_init6_2021-10-2221_51_24.592945/model-00026-1.30368-0.46154-2.10303-0.21000.h5\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 6.399999961104187e-08.\n",
      "Epoch 27/40\n",
      "34/34 [==============================] - 273s 8s/step - loss: 1.3187 - categorical_accuracy: 0.4299 - val_loss: 2.0358 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00027: saving model to model_init6_2021-10-2221_51_24.592945/model-00027-1.31868-0.42986-2.03578-0.24000.h5\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 274s 8s/step - loss: 1.3212 - categorical_accuracy: 0.4103 - val_loss: 2.1746 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00028: saving model to model_init6_2021-10-2221_51_24.592945/model-00028-1.32116-0.41026-2.17457-0.20000.h5\n",
      "Epoch 29/40\n",
      "34/34 [==============================] - 275s 8s/step - loss: 1.2580 - categorical_accuracy: 0.4736 - val_loss: 2.1562 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00029: saving model to model_init6_2021-10-2221_51_24.592945/model-00029-1.25795-0.47360-2.15619-0.15000.h5\n",
      "Epoch 30/40\n",
      "34/34 [==============================] - 275s 8s/step - loss: 1.2383 - categorical_accuracy: 0.4676 - val_loss: 2.1409 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00030: saving model to model_init6_2021-10-2221_51_24.592945/model-00030-1.23829-0.46757-2.14085-0.19000.h5\n",
      "Epoch 31/40\n",
      "34/34 [==============================] - 274s 8s/step - loss: 1.2819 - categorical_accuracy: 0.4495 - val_loss: 2.0984 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00031: saving model to model_init6_2021-10-2221_51_24.592945/model-00031-1.28194-0.44947-2.09843-0.21000.h5\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.2799999637991278e-08.\n",
      "Epoch 32/40\n",
      "34/34 [==============================] - 275s 8s/step - loss: 1.2764 - categorical_accuracy: 0.4540 - val_loss: 2.1296 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00032: saving model to model_init6_2021-10-2221_51_24.592945/model-00032-1.27636-0.45400-2.12961-0.20000.h5\n",
      "Epoch 33/40\n",
      "34/34 [==============================] - 276s 8s/step - loss: 1.3289 - categorical_accuracy: 0.4449 - val_loss: 2.2058 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00033: saving model to model_init6_2021-10-2221_51_24.592945/model-00033-1.32888-0.44495-2.20578-0.16000.h5\n",
      "Epoch 34/40\n",
      "34/34 [==============================] - 276s 8s/step - loss: 1.2701 - categorical_accuracy: 0.4555 - val_loss: 2.0385 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00034: saving model to model_init6_2021-10-2221_51_24.592945/model-00034-1.27007-0.45551-2.03852-0.23000.h5\n",
      "Epoch 35/40\n",
      "34/34 [==============================] - 277s 8s/step - loss: 1.3414 - categorical_accuracy: 0.4449 - val_loss: 2.1480 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00035: saving model to model_init6_2021-10-2221_51_24.592945/model-00035-1.34136-0.44495-2.14801-0.20000.h5\n",
      "Epoch 36/40\n",
      "34/34 [==============================] - 275s 8s/step - loss: 1.3354 - categorical_accuracy: 0.4268 - val_loss: 2.0969 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00036: saving model to model_init6_2021-10-2221_51_24.592945/model-00036-1.33544-0.42685-2.09689-0.21000.h5\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 2.559999856543982e-09.\n",
      "Epoch 37/40\n",
      "34/34 [==============================] - 277s 8s/step - loss: 1.3343 - categorical_accuracy: 0.4465 - val_loss: 2.0807 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00037: saving model to model_init6_2021-10-2221_51_24.592945/model-00037-1.33426-0.44646-2.08071-0.22000.h5\n",
      "Epoch 38/40\n",
      "34/34 [==============================] - 276s 8s/step - loss: 1.2802 - categorical_accuracy: 0.4389 - val_loss: 2.0836 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00038: saving model to model_init6_2021-10-2221_51_24.592945/model-00038-1.28018-0.43891-2.08357-0.22000.h5\n",
      "Epoch 39/40\n",
      "34/34 [==============================] - 278s 8s/step - loss: 1.3170 - categorical_accuracy: 0.4359 - val_loss: 2.0547 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00039: saving model to model_init6_2021-10-2221_51_24.592945/model-00039-1.31701-0.43590-2.05471-0.23000.h5\n",
      "Epoch 40/40\n",
      "34/34 [==============================] - 279s 8s/step - loss: 1.3243 - categorical_accuracy: 0.4404 - val_loss: 2.0697 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00040: saving model to model_init6_2021-10-2221_51_24.592945/model-00040-1.32426-0.44042-2.06974-0.22000.h5\n"
     ]
    }
   ],
   "source": [
    "history6 = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAD7CAYAAAAb+WdwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAACaDklEQVR4nOzdd1zVZfvA8c/NlukAQVEU9wQH7p27oZWWlllqZjurp/nU81S/6mnvZVZWlmWmZlZqZe4t7q2AirhYyhDZ9++PGxSRcYADh3G9Xy9eB875jusAyvf63vd9XUprjRBCCCGEEEKIysPO1gEIIYQQQgghhLiSJGpCCCGEEEIIUclIoiaEEEIIIYQQlYwkakIIIYQQQghRyUiiJoQQQgghhBCVjCRqQgghhBBCCFHJFJuoKaUaK6VWKqUOKKX2KaWmF7LdQKXUzpxtVls/VCGEEEIIIYSoGVRxfdSUUg2ABlrr7UopD2AbcKPWen+ebWoDG4ARWutIpVR9rXV0OcYthBBCCCGEENWWQ3EbaK1PA6dzPk9SSh0A/IH9eTa7HViotY7M2a7YJM3b21s3bdq0NDELIYSoYrZt2xartfaxdRxVhfyNFEKImqGov4/FJmp5KaWaAp2BzfleagU4KqVWAR7AB1rr2QXsPw2YBhAQEEBoaGhJTi+EEKKKUkodt3UMVUnTpk3lb6QQQtQARf19tLiYiFLKHVgAPKq1Tsz3sgPQFbgOGA78RynVKv8xtNYztdYhWusQHx+5sSqEEEIIIYQQBbFoRE0p5YhJ0uZorRcWsEkUEKu1vgBcUEqtAYKBw1aLVAghhBBCCCFqCEuqPirgK+CA1vrdQjb7FeinlHJQSrkCPYAD1gtTCCGEEEIIIWoOS0bU+gATgT1KqZ05z/0bCADQWs/QWh9QSi0DdgPZwJda673lEK8QQlS4jIwMoqKiSE1NtXUolZ6LiwuNGjXC0dHR1qEIIYQQVZolVR/XAcqC7d4C3rJGUEIIUZlERUXh4eFB06ZNMZMMREG01sTFxREVFUVgYKCtwxFCCCGqNIuLiQghRE2VmppKvXr1JEkrhlKKevXqycijEEIIYQWSqAkhhAUkSbOMfJ+EEEII65BEraa6EAt75ts6CiGEEEIIUQLnU9L5dsMxjsVesHUoopyVqOG1qEZCv4aVr0CDTuDdwtbRCCGK4e7uTnJysq3DEEIIYWOzNx7n3b9NB6yQJnUY07UR13ZsgFctKeJU3ciIWk0VF2Yej662bRxCCCGEEMJiG8JjaVnfnadHtOH8xQyeXbiHbq8u56EftrPyUDSZWdm2DlFYiSRqNVV8uHk8usa2cQghSkRrzZNPPkmHDh3o2LEjP/30EwCnT5+mf//+dOrUiQ4dOrB27VqysrKYNGnSpW3fe+89G0cvhBCiLFIzsth+/DwDW/tw/8Dm/P1Yf359sA+3dWvMurBYJn+9lV6vr+DVP/YTFi2zMKo6mfpYU8XlJGrH1kJ2NthJzi6EJV76bR/7TyVa9ZjtGnrywg3tLdp24cKF7Ny5k127dhEbG0u3bt3o378/P/zwA8OHD+e5554jKyuLlJQUdu7cycmTJ9m717S1PH/+vFXjFkIIUbG2HT9HelY2vZt7A6aAU3Dj2gQ3rs1z17VjxcFoFmyP4uv1x/h2w3Fm392dns3q2ThqUVpydV4TXTwHF+OhfntIiYPofbaOSAhhoXXr1nHbbbdhb2+Pr68vAwYMYOvWrXTr1o2vv/6aF198kT179uDh4UGzZs2IiIjg4YcfZtmyZXh6eto6fCGEEGWwITwWeztFt8C6V73m5GDHiA5+fHFnCBueuYbGdWtxz7ehHDht3ZuLouLIiFpNFBdhHrtOgqVPmumPfh1tGpIQVYWlI1/lRWtd4PP9+/dnzZo1/PHHH0ycOJEnn3ySO++8k127dvHnn3/yySefMG/ePGbNmlXBEQshhLCWDeFxBDfywt256Ev4+p4uzL67Bzd/up5JX29hwf29aVTHtYKiFNYiI2o1Ue76tMB+ULe5rFMTogrp378/P/30E1lZWcTExLBmzRq6d+/O8ePHqV+/Pvfccw93330327dvJzY2luzsbMaMGcPLL7/M9u3bbR2+EDXG8bgLDHp7FQ/+sJ0VB89KgYdq7kJaJrfO2MiiHSfL7RzJaZnsjkq4NO2xOP61a/HtlO6kpGdx56wtnLuQXm6xifIhI2o1UVw4oKBOIDQbALt/hqxMsJdfByEqu5tuuomNGzcSHByMUoo333wTPz8/vv32W9566y0cHR1xd3dn9uzZnDx5ksmTJ5OdbS4QX3vtNRtHL0TNoLXmxcX7OJOQyvmUdP7YfRpvd2du7NSQm7s0ol1D605DTkzNIDIuhfYNPaXpvI3MWB3OlmPxRMQmM6y9L65O1r+m2no0nqxsTe/mlq85a+PnyZd3hjBx1hamfLuVOVN7lEtsonzIT6omio8Ar0bg6AKB/SF0FpzeCY1CbB2ZEKIQuT3UlFK89dZbvPXWW1e8ftddd3HXXXddtZ+MoglR8ZYfiGbloRiev64td/ZqyqpDpsDDtxuP8eW6o7Rt4MmYLv6M7uSPj4dzmc6Vla2Z+k0oW47F06lxbe4b0Iyh7fywt5OEraJEnUth5poIghp5sTsqgdkbj3PfgOZWP8+G8FicHOzo0qROifbr0aweH47vzANztvHQDzv4fGJXHO1lUl1VID+lmig+HOo2M5837WcepZ+aEEIIUWYX07N4cfE+Wvm6c1fvpjg52DGsvR+fTwxh87+H8NKo9jjZK1754wA9X/uHqd+GEpecVurzfbwijC3H4pnQI4D4C+nc9/12hr67mh+3RJKakWXFdyYK88ayQygFM+7oysDWPsxYHU5SaobVz7MhPI6uAXVwcbQv8b4jOvjxf6M7sOJgNP9euKfQ9c7l4WxiKi8u3seKg2cr7JzVhSRqNVFcONTLudPj5g2+HWSdmhBCFEEpNUIpdUgpFaaUeqaI7boppbKUUmPzPHdMKbVHKbVTKRVaMRELW/lsVRgnz1/k/0Z3uGrUoq6bE3f1bsqvD/Xl78f6M61/M9YeieH+77eTnlnyNWyhx+L54J/D3NTZn1dv6sjKJwby8e2dcXN24NmFe+j35ko+XRVGwkXrJw1FqcgkwNa2HY/nt12nmNavGQ1r1+JfQ1tzPiWDWeuOWfU85y6ks/90Ir1KMO0xvzt6NuGRwS35eVsUb/91qNDtsrM1e6IS+GRlGLfN3MRjP+3kRHxKic+ntWbulkiGvLuabzYcY8o3oUyfu6NMNyZqGpn6WNOkxEPqeVNEJFfu9MeMVDMdUgghxCVKKXvgE2AoEAVsVUot1lrvL2C7N4A/CzjMIK11bLkHK2zqWOwFZqyJ4MZODYvtXdXS14OnR7ShjZ8H0+fu5PlFe3hjTJDFa8wSLmYwfe5OGtVx5f9Gm2q09naK64Macl3HBmwMj2PGmgjeXHaIT1eGc3uPAMZ1a0xgPTfsynFa5IqDZ3l83i56Btbj6ZFtCPR2K7dz2Vp2tub/fj+Ar6cz9+ZMdezYyIvh7X35cm0Ed/VuQm1XJ6uca/PROLSmROvTCvLYkJbEJKXxycpwfNydmdQnEIDopFTWHo5lzZEY1h2JJS6n8EgbPw92nDjHH7tPc1fvJjw0qCVero7FnudY7AWeXbiHjRFx9GxWl5dHd+CPPaf5ZGUYa4/E8sIN7RgV3FDWVBZDErWaJrfRdb18idqmTyFqq6kEKYQQIq/uQJjWOgJAKTUXGA3sz7fdw8ACoFvFhicqA601L/62Dyd7O/59bVuL9xvdyZ+w6GQ+WhFGK18PpvZrZtG5nvtlD2cTU/n5vl54uFx54ayUoncLb3q38GbfqQRmrongq3VHmbkmAjcne9o08KRtAw/aNvCkbQNP2vh5lLnAhNaaL9ce5X9LDxDo7caaIzEsP3D20ihOXTfrJCyVya+7TrLrxHneuSUYtzzl8h8b2oq/9q9l5poInhrRxirn2hAeh6uTPUGNapfpOEopXh7dntjkNF76fT/7Tyey52TipV5r9dyc6NfSm/6tfOjX0gcfD2fOJKTy7t+H+HLdUeaFRvHI4JZM7NkEJ4erJ+ZlZmXz9fpjvPP3IRzt7Hjt5o6MC2mMnZ3iUV8PRnZowFMLdjN97k5+3XmKV27sQMPatcr0nqozSdRqmtzS/HlH1Jr0AWVvpj9KoiaEEPn5AyfyfB0F9Mi7gVLKH7gJuIarEzUN/KWU0sDnWuuZBZ1EKTUNmAYQEBBgnchFhfl7/1lW5RQQqe9Zstkpjw1pRVh0Mv9bcoDmPu4MalO/yO3nb4vi992neXJ4azoHFF1Yon1DLz4Y35knh7dmfVgsB04nsf9UIr/uOMX3myIBUAoC67nRtoEnQ9v5Miq4YYlG3dIys3j+l738vC2Kazv68c4tnUhKy+C9v48we+MxFmyP4qFBLbird9NSra+qjFLSM3lj6SGCGnlxU2f/K15r4+fJDUEN+Xr9Mab0DcTbvWwFY8Akat2a1i0wOSopB3s7PrqtM3d+tYWF20/StUkdnhzemgGtfGjXwPOqn72flwtvjg1mUu9AXlt6gJd/38/sjcd4ekQbRnbwuzQqduB0Ik8v2M3uqASGtPXllRs74Od15b+F1n4eLLy/N99sOMbbfx5i2HtreGZkG27vHlCuI71VlSRqNU1cOCg7qNPk8nMuntCwc846tedsFpoQQlRSBV095F+E8z7wtNY6q4CpPH201qeUUvWBv5VSB7XWVy0MzkngZgKEhITUnEU+1cDF9Cxe+m0/rX09uKt30xLvb2eneOfWYCJnpPDwjztY+EBvWvl6FLhtREwyLyzeR89mdUtUWbBRHVfGdbt8A0BrTdS5i+w/bUZTDpxOZEfkOf7Yc5ov10Xw72vbWtSvKy45jfu+38bWY+d4ZHBLHh3cEjs7RS0ne167uSOT+zTltSUHeG3pQWZvPM5TI1pzQ1DJEsHyNm/rCU4npPLgoOY4WFgNceaaCM4kpvLR7Z0LfC/Th7Tk992n+GxVOP+5vl2Z4otOTCUsOplbujYq03HycnG054d7epCRpanlZFny3K6hJ7OndGf14RheW3KQB+Zsp0tAbZ4e0Yb1YbF8uiocr1qOfHx7Z67r2KDQaY32doq7+wYyrJ0vzy7cw/OL9rJ41ylev7kjzXzcy/S+NobHMWfzccZ1a0zfFt5VfmqlFBOpaeLDTWl+h3x3dwL7w8lQSEu2TVxCCFF5RQGN83zdCDiVb5sQYK5S6hgwFvhUKXUjgNb6VM5jNPALZiqlqEY+vVRApH2py567OjnwxZ0huDjac/e3W4kvoDlxemY20+fuxMnBjvfGdSpTCX6lFI3rujK8vR+PDmnF5xNDWPf0Nbw/rhPnLmRw+xebmfrtVsKikwo9xsEziYz6eD27oxL46LbOPD601VVJSytfD76e3J3v7+6BZy1Hps/dyU2frmdDeCxpmbavSpmdrXnzz4O8t/wwk7/ZalHhldMJF5mxOpzrghrQrWndArdp7uPOzV0a8d2m45xJSC1TjBsj4gAsbnRtKQd7O4uTtFxKKQa2rs+S6f14/eaOnDh3kXEzN/HhijBGBTdk+eMDuD7IsrVnjeu68t3d3XlzbBAHTycy8oO1/HOg9JUhw6KTmfZdKH/sOc3Er7Zw/UfrWLzrVJVuNi+JWk0TF37ltMdcgf0hOxMiN1V8TEIIq3N3L/yu5LFjx+jQoUMFRlPlbQVaKqUClVJOwHhgcd4NtNaBWuumWuumwHzgAa31IqWUm1LKA0Ap5QYMA/ZWbPiiPB2NvcDnqyO4qbM/PYopIFKchrVr8cWdXTmbaEap8leCfOevQ+w5mcAbY4Jo4GX9dT12doobO/vzz78G8PSINmyOiGf4+2t5ftEeYvNV6lu+/yxjPt1ARlY28+7txQ3BDYs8dt+W3vz+cF/eviWYs4lp3P7FZlo/v4ygF/9k8DurGD9zIw/9sJ2XftvHp6vCmBd6gm3Hz1n9Pea3+2QCscnpjOzgx8bwOG76dD1HYy8Uuc+byw6RreGZYtafTR/ckuxszccrj5Qpxg1hcXi6OFi9UXpZ2NspxncPYNUTA/m/0e35/u4evDuuE3VKuBZRKcWtIY1Z/vgAWvt58OAP20v1cz+fks7Ub7fi7GDHin8N5M0xQVzMyOKRH3cw8O1VfLvhGBfTbX9joKQkUatJtDbNrusVkKg17gH2TnB0VYWHJYQQlZnWOhN4CFPN8QAwT2u9Tyl1n1LqvmJ29wXWKaV2AVuAP7TWy8o3YlFRtNa89Ns+nB3sePZa6xSN6BxQh7fGBrHlaDz//XXvpVL3a4/E8PmaCCb0CGB4ez+rnKswLo723D+wOaueHMgdPQKYu+UEA99axScrw7iYnsXnq8O557tQmvm4s/ihvgQ3rm3Rce3tFGO7NmLlEwN555Zg/jW0FTd29qe1nwdZ2Zq9JxP4OTSKN5cd4qn5uxnz2QbmbT1R/IHLYOXBaOwU/O+mjnw/tQfnLqRz4yfr2RBWcJHWnSfO88uOk9zTL5DGdV2LPHbjuq6M69aYn7aeKFV5+1wbImLp2axepWxi7ubswJ29mtK3ZdlG++p7ujBrUjf8PF24u5iR3PwysrJ5YM52Tp1P5fOJXQn0duPWbo1Z/tgAZk7sSn0PZ15YvI/er//D+8sPFzhaXVKnEy7y09ZI/tp3pszHKoqsUatJUuIgLbHgETUnV2jUXfqpCVGcpc/AmT3WPaZfRxj5epGbPP300zRp0oQHHngAgBdffBGlFGvWrOHcuXNkZGTwyiuvMHr06BKdOjU1lfvvv5/Q0FAcHBx49913GTRoEPv27WPy5Mmkp6eTnZ3NggULaNiwIbfeeitRUVFkZWXxn//8h3HjxpX6bVclWuslwJJ8z80oZNtJeT6PAILLNThhM3/lFBD57/XtqO9hvfY2ozv5c/hsEp+sDKelrwc3dmrI4/N20bK+O89fV7b1TiVRz92Zl0Z34M7eTXlj6UHe+vMQM1aFk5SWyXVBDXh7bHCJp84B1HKyZ0wR661S0jOJTUrn2V92859f99KuoScd/L3K8lYKtfJQNJ0D6lDHzYmezerx64N9ufvbrUyctYWXRrXnjp6X1/Rrrfm/3/bh4+HM/QNbWHT8h65pwc/bovhoxRHeHFvy/wpOxKdwIv4id+eU0a/OvN2dmT2lBzd/tsEUOnmgz1XFSAry0m/72BAexzu3BNO1yeWpqHZ2imHt/RjW3o+tx+L5fHU47y8/wuerI7guqAFBjbxo18CTNg08cXcuOiVKzchi89F41hyOYc3hGI5Em6VCIzuY45eXYhM1pVRjYDbgB2QDM7XWHxSybTdgEzBOaz3fmoEKKyioNH9ezQbAyv+ZXmuuBc+5FkLYxvjx43n00UcvJWrz5s1j2bJlPPbYY3h6ehIbG0vPnj0ZNWpUiRZPf/LJJwDs2bOHgwcPMmzYMA4fPsyMGTOYPn06EyZMID09naysLJYsWULDhg35448/AEhISLD+GxWiiriYnsX//bafNn4e3NmrSfE7lNC/hrYmLDqZV//Yz8LtUSRczGD2lO6lSozKqrmPOzPvDGHLUdNgu1ezejw4qEW5FWpwdXIgoJ4DH47vzPUfreOBOdv57aG+FvXvKonopFR2RyXw5PDWl54LqOfKwgd688iPO3h+0V6OnE3iP9e3w8Hejt92n2Z75HneHBNU7IV9rgZetbijRxO+3XiM+wY0L3GxjEvr01pYd31aZRVQz5VvJndj/MxN3DVrC/Pu7VXkz332xmN8vymSewc0KzL579a0Lt2a1uXI2SQ+XxPB8gNnmb8t6vJ567rStoEH7Rp4XWpdcTEjizWHY1h9OIYtR+NJy8zGycGOHoF1uTWkMf1b+dDKt2zFT4pjyW9ZJvAvrfX2nHn225RSf5ew0aeoDAoqzZ9XYH9Y+SocXw9tb6i4uISoSooZ+SovnTt3Jjo6mlOnThETE0OdOnVo0KABjz32GGvWrMHOzo6TJ09y9uxZ/Pwsv7u3bt06Hn74YQDatGlDkyZNOHz4ML169eLVV18lKiqKm2++mZYtW9KxY0eeeOIJnn76aa6//nr69ZN2HqLm+mSlKSAy795eFlcKLAk7O8W7t3Zi7IyN7DuVyAs3tKNtA9uuUeoeWJc5U3tW2PnquTvz8e1dGPf5Rv71805mTgyxarXIVYdiABjY2ueK5z1cHPnyrm68vvQAX6w9SkTsBd65JZjXlxygfUPPIhOCgtw/sDk/bonkg3+O8MH4ziXad2N4HN7uTrSsX74JQWXSwd+LmRO7ctfXW7hndiiz7+5eYFuHtUdieOm3/QxpW5+nhls29bilrwdv3xKM1poziansP5Vb9TSJ/acT+Wv/WXS+mrst6rszoUcT+rfypkdgvQq9WVJsoqa1Pg2czvk8SSl1ANNTRhp9VjVx4aZfWp1C7vw17AKObmb6oyRqQlQ6Y8eOZf78+Zw5c4bx48czZ84cYmJi2LZtG46OjjRt2pTU1JJVF9P5/yLluP322+nRowd//PEHw4cP58svv+Saa65h27ZtLFmyhGeffZZhw4bx3//+1xpvTYgqJSw6mZlrTAGR7oHlNwPFzdmBb6d0Y0NYHKM7FV2so7rq2qQOz1/Xlhd/289nq8N5cJBlUw4tsfJgNH6eLrQrIAG2t1M8d107Wtb34LlFexj49ipS0rN4txTVNn08nLmrd1M+XxPOAwNb0Nqv4NYL+Wmt2RAeS6/mVb/MfEn1buHNu7d24pG5O5g+dwefTuh6xfc9IiaZB+dsp2V9d94f37nEPxOlFA28atHAqxaD2/peev5CWiaHzppeg472ir4tffC3YUPuEt0CUko1BToDm/M9n9vos8D5+nm2m6aUClVKhcbExJQwVFFm8eFQOwDsCxlCdnCCJr1knZoQldT48eOZO3cu8+fPZ+zYsSQkJFC/fn0cHR1ZuXIlx48fL/Ex+/fvz5w5cwA4fPgwkZGRtG7dmoiICJo1a8YjjzzCqFGj2L17N6dOncLV1ZU77riDJ554gu3bt1v7LQpR6WVna55duJtaTvb8+9q25X6++h4u3NjZv8ZdqOd1V++m3BDckHf+OlRokY+SSs/MZu2RWAa18Snye3trt8bMmdqTWo723BDckJ6lrOx5b/9muDk58N7fhy3eJyL2AmcT0+jdvGzVRKuqG4Ib8t/r2/HnvrNXFNZJSMlg6rehONrb8cWdIRZPQ7WEm7MDXQLqcEfPJozrFmDTJA1KkKgppdwxI2aPaq0T8738PjmNPos6htZ6ptY6RGsd4uPjU9SmojzEhRe+Pi1XYH+IOQhJpe9jIYQoH+3btycpKQl/f38aNGjAhAkTCA0NJSQkhDlz5tCmTcmrzj3wwANkZWXRsWNHxo0bxzfffIOzszM//fQTHTp0oFOnThw8eJA777yTPXv20L17dzp16sSrr77K888/Xw7vUojK7cetkWw9do7nrmuLj4dz8TuIMlNKXWqG/PCPO8rclwwg9Hg8yWmZDGpdv9htuwfWZcOz1/DeraWvC1THzYm7+waybN8Zi8vPbwjP7Z9WMxM1gMl9Arl/YHPmbI7kw3/CyMjK5sEftnPiXAozJnYttvJmVacKm/ZyxUZKOQK/A39qrd8t4PWjQO7tCG8gBZimtV5U2DFDQkJ0aGhoaWIWpaE1vNYIOk2Aa98sfLtTO2DmQLj5Swi6pcLCE6IyO3DgAG3blv+d8+qioO+XUmqb1jrERiFVOfI3snI6m5jKkHdW07GRF3Om9qjRo1y2EBadzOiP19Haz4O503rh5FD6tYGv/rGfbzccZ8d/h+JmxRGZoiSmZjDy/bVkZmez+KG++HoWXdHwgTnb2HUigXVPD6rRv2taa574eTcLtkfRtUkdth0/x1tjg7glpLGtQ7OKov4+FvsbrsxvxlfAgYKSNCi80WfpQxZWlxwN6clQt1nR2/kFgUttOLq6QsISQgghqooXF+8jPSub/93UsUZfONtKi/ruvDE2iO2R53lt6YEyHWvFwWh6NKtbYUkagKeLI1/cGUJSaibTZoeSmlH4RLTsbM3G8Dh6Na9X43/XlFK8PqYjg1r7sO34Oab1b1ZtkrTiWPLb2QeYCOxRSu3Mee7fQAAU3kdGVDLxxZTmz2VnD037Wm+dWnYWbJ8N3i3NcYUQFWbPnj1MnDjxiuecnZ3ZvHlzIXsIIQrz174zLN17hqdGtKapt5utw6mxrg9qyLbj5/h6/TG6NqnD9UElL7ISGZdCeMwFJvSwfluF4rRr6Ml74zpx73fbeHL+bj4c36nAROzgmSTOpWTQq5Rr4qobR3s7Pp3QlQ3hsQy0YLpqdWFJ1cd1XJ7WWKy8jT5FJRIfYR6LG1EDCBwAB3+Hc8egTtMynPMoLLofIjeCux9M3wmOtl2UKURpaa2r3F3Njh07snPnzgo9pyXT6YWoapJSM/jvr/to4+fBPf0s+DsqytWzI9uyOyqBp+fvpo2fBy3qW1ZFMdeKg2Yd/jVtbHPBP7y9H08Ob81bfx6iVX13Hh7c8qptNoSboim9avD6tPxqOdlfUaGxJrB+4w9ROcWFg50D1Lbg7lFgf/N4dG3pzqW1GUWb0RfO7oc+0yH5DITOKt3xANKSYf7dcHp36Y8hRCm5uLgQFxcnSUgxtNbExcXh4lL0ugshqpo3lx3ibFIqr48JwrEceqaJknFysOOT27vg4mjP/d9vJz0zu0T7rzwUQzNvN5uOjD4wsDk3dfbnnb8Ps3TP6ate3xgeR6C3Gw1tXHVQ2FbFTcwVthUfbpI0ewt+5D6twa2+mf7YZWLx2+eVHA2LH4HDS03Cd+Nn4NUITu2Ede9B10ngVIr/GNd/AHvnQ2YqjJ9T8v2FKINGjRoRFRWFtBUpnouLC40alawZrBAV6aEftnMmIZVXbupAG7/iG0hvOx7P95uPM6l3Uzo1rl3+AQqL+Hm58NYtQUz5JpQfNh9nUp9Ai/ZLSc9kY0QcE3tW/LTHvJRSvHZzR47FXeDxebtoXNeVDv5eAGRmZbP5aDyjamjvPHGZJGo1RVxE8evTcillkqyja8zomKXTvQ7+YZK0tCQY/hr0uA/scu48XvM8fDUUtsyEvo+VLPbzkbDhQ3Byh0NL4PwJqF0zFpGKysHR0ZHAQMsuAoQQldfaIzH8vvs0TvZ2XP/hOh4Y2JwHr2mBs4N9gdunZWbxzII9NPSqxRPDWldwtKI4g1rXp3fzeny4IowxXRvh4VJIn9g8NoTFkZ6ZbbNpj3m5ONrz+cSu3Pjxeu6ZHcqvD/ahvqcLe04mkJyWWaPL8gtDxu9rAq3NGrW6FiZqAM0GmOmKsRY0ZkxNhEUPwtzbwbMh3LsGej1wOUkDaNwdWgw1I2Op+dvwFWP5i+ZxwnzzWJYplEIIIWqk7GzN60sP4l+7FmufHsSo4IZ8uCKM6z5cV2hfqxmrIjgSncwrN3ao0OqAwjJKKZ4Z2Yb4C+l8sSbCon1WHIrGzcmebk3rlnN0lqnv4cIXd4VwPiWDad9tIzUj61L/tNI21xbVhyRqVc2ZPfD1dRBzyPJ9ks5AxgXLR9Qgzzq1Aqo/am0aYh/fCNu+hRl9YNcP0O8JmPoP1C+k6e6gf8PFc7C5BIVCIzfB3gXQ+xFo0gtaXwvbv4WMsje7FEIIUXP8tvsU+04l8sTwVvh6uvDuuE58PbkbKWmZjJ2xgRcX7+NCWual7cOik/hkZRg3BDdkUCUYfREFC2pUm+uDGvDF2qNEJxZ9baC1ZuXBaPq29C5TDzZra9/Qi/fGBbPzxHmeXrCbjeFxtPHzwNtdGqrXdJXnt1QUL/YIzL4Rjq8zxToslVua35KKj7nqNIXaAbD/V3Ou5S/CvDvhs77wP394pxV8PQJ+e8QUKZnyJwz+Dzg4FX5M/y7Q+jrY8LFJ2IqTnQ3LngGPBtD3UfNc93sgJQ72/WL5exFCCFGjpWVm8fZfh2jbwJPRwf6Xnh/Uuj5/PT6AiT2b8M2GYwx7bw1rDseQna3598K91HKy57/Xt7Nh5MISTw5vTUZWNh/8c6TI7Q6eSeJ0QmqlmPaY34gODXhyeGt+3XmKdWGxUu1RAJKoVR3njsPs0Wa9WINgsx7M0gp0cRb2UMuv+TVwbC0sftgkV2f3m6mNXe6EkW/BHQvgkR3wUKiZ2miJQf+GtATY+Enx2+7+CU7tgCEvXi5AEjgAvFuZtW5CCCGEBX7YHMmJ+Is8M7INdnZXrrt2d3bg/0Z34Of7euHsaMeds7YwdsYGthyL57lr2+LjIaMalV2Tem5M6BHA3K0nCI9JLnS7lYeiAZOgV0YPDGzOjTkFRHo397ZxNKIykAnXVUHiaZg9CtIvwKQ/4MQm+ONfZvpjYdMM84oPBztH8CxhJbYhL0GHMaZapFcj0wy7rPw6QLsbYdNn0ON+cCvkjlFashnF8+8KHW+9/LxS0H0aLHkCorZBo65lj0kIIUS1lZSawUcrwujdvB79WxZ+8dutaV2WPNKPj1YcYcbqCHo1q8ctIVLBtKp4eHBL5m+L4u0/D/HZHQVfG6w8GE0Hf0/qe1bOFiJKKV4fE8Tgtr6VctRPVDwZUavsLsTBdzfChVgzguXXAVqNNK8dWmLZMeIjzFRGS0rz51WrtlmrVqeJdZK0XAOfNUnnhg8K32b9+6aYyYjXryxKAhA8Hpw8YOsX1otJCCFEtTRzTQTxF9J5ZmSbYpvWuzja8+TwNqx5ahBf3hVS5Zrc12Te7s5M69+cpXvPsD3y6uUV51PS2Xb8HNdU0tG0XC6O9twQ3BB7O/ndE5KoVW6pCfD9zXDuGNw2FxqFmOe9/KFBJ8sTtZKU5q8I9dtAx1tgyxem71p+5yNhw0dmm4KmVDp7QKfbTJGRC7HlH68QosZTSo1QSh1SSoUppZ4pYrtuSqkspdTYku4rrC86MZUv1x7l+qAGBDWqbfF+/rVrSZXHKmhqv0C83Z15fclBdL7lIasPx5CtYaCMVIkqRBK1yio9BX4YB2f3wq2zIbDfla+3uQ6iQk31xaJkZ5e8NH9FGPgMZKaZJtj5/f0CoMzatMJ0mwpZ6aYCpBBClCOllD3wCTASaAfcppS6qsJEznZvAH+WdF9RPt7/5wgZWdk8OVx6oNUEbs4OTB/Ski3H4llx8MobwSsPRlPXzYngEiTsQtiaJGqVUWYa/DQBTmyGMV9Cq+FXb9N6JKDh8LKij5V0GjIvQr0SVHysCPWaQ/BtsPUrSDx1+fnITbBvIfSZbtbFFcantSkssnUWZGUWvp0QQpRddyBMax2htU4H5gKjC9juYWABEF2KfYWVhcck89PWE0zoEUCTem62DkdUkPHdGhPo7cYbyw6SlW1G1bKyNasPxzCwlY9MKRRViiRqlU1WJsyfAuEr4IYPof1NBW/n2wG8AuDQ0qKPd6k0fyUbUQMY8CToLFj7jvk6OxuWPg0eDaHPI8Xv330aJEbB4WK+B0IIUTb+wIk8X0flPHeJUsofuAnI3yiy2H3zHGOaUipUKRUaExNT5qBrureWHcLFwY6HB7e0dSiiAjna2/Hk8NYcPpvMgu1RAOw8cZ5zKRnSD09UOZKoVSbZ2fDrg3DwdxjxBnSZWPi2SplRtYiVpjBHYUpbmr8i1GkKnSeaptnnI2H3XDi9E4a+dLkcf1FajQCvxrYp1b/2XZNQCyFqgoJuwefvj/I+8LTWOqsU+5ontZ6ptQ7RWof4+PiUPEpxyfbIcyzbd4Zp/ZtL0+AaaGQHP4Ib1+a9vw+TmpHFyoPR2Nsp+reSf1eiapFErbLQGpY9bZKVQc9Dz/uK36fNtZCZChGrCt8mPhzsnUtemr+i9H/CJJ3LXzIf/iHQYWzx+4GpYhkyBY6ugeiD5RtnXsnRsPpN2LsQLp6vuPMKIWwlCmic5+tGwKl824QAc5VSx4CxwKdKqRst3FdYkdaa15ccxNvdman9Am0djrABpRTPjGjD6YRUvt1wjBUHo+napA5etRxtHZoQJSKJWmWx8n9mZKjXQyZ5sUSTPuDsBQeLqP4YFwF1A68ucV9ZeDWCrpNh7/zCy/EXpcudJhGtyFL9Gz406/7QcGJLxZ1XCGErW4GWSqlApZQTMB5YnHcDrXWg1rqp1ropMB94QGu9yJJ9hXWtOBjNlmPxTB/SUio31mC9mtdjUGsfPloRxv7TiZW2ybUQRamkV+9V0G+Pwk8TISW+5Ptu/ATWvGmmAQ57xYwwWcLeEVoONQVFsvPPtskRH14516fl1e9xcHKHoPHQuFvJ9nXzNk25d82F1MTyiS+vC7GmAErbG8DOASI3lv85hRA2pbXOBB7CVHM8AMzTWu9TSt2nlCpy+kNh+5Z3zDVVVrbmjWUHCfR2Y3y3xsXvIKq1p0a04UK6KTgmDaRFVSS3mqzh3HHY9g2gzRqrW7+Dhp0s23fH9/Dnv6HtKLjhA8uTtFytR5rRqKitENDzyteysyH+KLQYUrJjVjQPP3hkB7jWK93+3afCrh9MstZjWuHbnTsG6z80lSVv/wlql+KP+IaPIOMiDH7BVKuM3FS6mIUQVYrWegmwJN9z+QuH5D4/qbh9RflYsD2Kw2eT+XRCFxzt5V50Tde2gSe3dQ8g9Fg8rXzdbR2OECUm/4tZw47vzOMt35qRrVnDYcec4vfbvxgWPwzNBpky/Hb2JT93y6Fg51hw8+vEk5CVVjkLieTnXr907x/Av6v52DLTrPXL7+x+WHAPfNgFts+GuDD4418Fb1uUC3GmSXeHMeDdEgJ6wcltpp2CEEIIm8rIyubDf44Q1MiLkR38bB2OqCReGd2BJY/0Q5X0RrgQlYAkamWVlWlGxVoMgfY3wr1roHF3+PUBMx2ysIv48JWw4G6TYIz7HhxKWZXKxQua9i14nVplLs1vbd2nQdyRKwurnNgKP94Gn/WCg39Az/vh0d0w5AU48qfp11YSmz6BjBTo/6T5OqCXSYRP7bDa2xBCCFE6v+w4SdS5i0wf3FIuysUldnYKBxldFVWU/OaWVdjfpql017vM127ecMcv0Pcx2PY1zBoBCVFX7nNiK8ydAPVawoSfwbmMw/GtrzVJSuyRK5+vzKX5ra3djeDqbUbVwlfAN9fDV0Pg+AYY+Cw8theGvwqeDaHHfdCws+nZZumawpR42DzTJOP125jncqeayjo1IYSwqcysbD5ZGUb7hp6yFkkIUW0Um6gppRorpVYqpQ4opfYppaYXsM0EpdTunI8NSqng8gm3Etr2Dbj7mp5euewdYMiLZqQs9gh83v/ySM/Z/TBnrJnqN3Eh1KpT9hhajzSP+ac/xkeAg4tpIF3dObqYZPnQEvjuJjO9cdir8Ng+GPgMuNa9vK2dPYz6yCRff//HsuNv+gzSky6PpoFJyuu1lHVqQghhY4t3neJ4XAqPyGiaEKIasWRELRP4l9a6LdATeFAp1S7fNkeBAVrrIOBlwAYdiG0g4SQc+Qs6TTAVGPNrewNMWwluPiZ5WP6SeXSsBXcuMkU0rKF2Y/DrePX0x7hwqNus8pbmt7bu90Kb601Rlum7oPdDhY9W+nWE3g+baatH1xR93IvnYfMMU/DFt/2VrwX0NIladrZV3oKopKJC4Z+X5ecsRCWUla35eGUYbfw8GNrW19bhCCGE1RR7Ba+1Pq213p7zeRKmvLB/vm02aK3P5Xy5CdPQs/rbOQd0NnSZWPg23i1h6j9mat66d82apom/QJ2m1o2l9XVwYrMpH58rPidRqyk8fGH8HOg6ybI1fwOeNj+H36abSo6F2TwD0hJhwFNXv9akN6Seh5gKbLgtKlbiKfhxPKx92/wbE0JUKn/sOU1EzAUeGdwSOzsZTRNCVB8lGmpRSjUFOgNFXa3cDSwtZP9pSqlQpVRoTExMSU5d+WRnmQqCzQYWnww5u8PYWeZj8lKo39b68bQeCWjTUy03vnPHasb6tNJycoXr3zdTRNe8VfA2qQmw6VMzUufX8erXZZ1a9ZaVAT9PhvQUM414z8+2jkgIkUd2tuajf47Qsr47I9pLpUchRPVicaKmlHIHFgCPaq0L7CyslBqESdSeLuh1rfVMrXWI1jrEx8enNPFWHuErIeEEdLnLsu2VMmXdyyNJA2gQDJ7+cCgnR044AVnpNaPiY1k0HwTBt8P6D+DM3qtf3zzTJGt516blVSfQrFEsr3VqmWlmyt3ueabCqKhYy1+EE5tg1IfmZsj+RSZ5E0JUCsv2neFIdDIPy2iaEKIasihRU0o5YpK0OVrrAmuaK6WCgC+B0VrrOOuFWElt/8Y0aG5zna0jMZQyF5LhK8w0vtyKjzVp6mNpDX8VXGrDb4+YkchcaUmw8WNoNbLwBuZKXV6nZm2ZaTDvLjPlbuE98FEX2PoVZKRa/1ziavsXm59/t3ug41joeAukxEHEaltHJoTAjKZ9+M8Rmvm4cV3HBrYORwghrM6Sqo8K+Ao4oLV+t5BtAoCFwESt9WHrhlgJJZ01I1edbi99/7Py0Ppa0+crYrWZzgcy9dESrnVhxOumefWWLy4/v2WmWX9W0Nq0vAJ6QULk1W0YyiI3STu8FK59G8b/aIrS/PE4fBBkRgDTkqx3vor28yT4tDeseMX0oStp8/HyFhcOvz5o+hwOf9U812KI6Vso0x+FqBSWHzjLwTNJPDSoBfYymiaEqIYsGVHrA0wErlFK7cz5uFYpdZ9S6r6cbf4L1AM+zXk9tLwCrhR2zoHsTMunPVaUpn3ByQMO/WESNUdX8JC7jBbpONZciP/zf3D+BKQlw4aPoeUw8O9S9L4BvcyjtUbVMtMvJ2nXvQPd74E218LU5XDXb2b67N//hffaw4pX4UIVG8A+sxf2/WJuKqx9B2YOhPc6wJKnTAVOW0/xzLgI8+40bRxu+ebyzRgHZ1PJ9eDvRRefEUKUO601H644QpN6rowKrgEtaIQQNZJDcRtordcBRd6q0lpPBaZaK6hKLTvbFBFp0tdUdKxMHJyh5RA4tMysWavbzEzNE8VTCq57Fz7tCX/8y1RzvBhvKkMWx7cDOLmbgiIdx5Ytjsx0kyTkjqR1y/PPSikI7G8+Tm6Dte/CmjfN9Lwud0HIFPBpVbbzV4StX5jCHPesMCNph5fBwT9g+7ew5XPTW7DVCFPApdnAsjeEL6klT8DZfaYZfe2AK1/reItp6XB4GbS/qWLjEkJcsvJQNHtPJvLm2CAc7GtICxohRI1TbKIm8jm2Bs4dhUH/tnUkBWt9rRmtOLr6yibconh1msA1z8Of/zYNypsPhkYhxe9n7wCNupV9RC0zHX7OM92x+z2Fb+vf1bQiiD4I69830zQ3fwYNO0PQeFO4xr0SFuy5eM4URul4y+Um5J0nmI/0C2aN5YHfzdTiXT+CXc73NnCASdr8u4KDU/nFt/07k4j1fwpaDr369ab9TPGYPfMlURPCRrTWfPBPGI3q1OKmzv7F7yCEEFWU3IYqqW3fmsITbUfZOpKCtRwKyt5UfJT1aSXX4z6T7GSlWTaaliuglxmFuXi+dOfNTDfrtg4tKT5Jy6t+G7hpBjy+H4a9aqbkLnsa3mkNc26FvQsq1zS9nT+YKY8FvT8nNzO18ObP4ckwuHOxaUqemQqr34CvR8AbTeH7sbDhIzi927oNqE/vNqNpgQNg4DMFb2NnD+1vhiN/l+5nveQpmDuh9L8nQgjWHIll14nzPDioBY4ymiaEqMZkRK0kLsSa9Skhd4Oji62jKVitOmba3rG1Upq/NOzsYdz3EBUKAT0s369JL0DDiS3QaljJznkpSfujZElaXh5+0Psh83F2P+z+yRS9mP+nWbfYbrQZtWrSu+THtpbsbNj6JTTuaabmFsXeEZoNMB9gRuKOrTMjnRGr4a+/zfOu3qbYS/dpZZvme/G8mXJaqy6M+cr8HhSm41gzennwd+h8h+XnOLndTO0EU6xkws9Qu3HpYxaiBtLaVHps6OXCmC6NbB2OEEKUK7kVVRK7fjQjVV0rWRGR/HJbBsiIWul4NYL2N5ZsH/+uZppeSRtfZ6bD/MllS9Ly820HQ1+CR/eYUal2o0z/r69Hwm4bViwMX2GK3JTmPdaqY0bbrnsHHg6Fx/bDjZ+BXwdY+hT8eFvpi6pobSo8JpyAW74ufsqof1eo09RMfyyJf14yLT3G/wCJJ+HLIWYUTwhhsY3hcWw7fo77B7XAyUEuYYQQ1Zv8L2cprc20x0bdy69ptbV0udNc9DcuwYiQKBsnNzNKVNJ1aovuMyMzI9+yTpKWl529GZG68VN44ogZyfrjX9ZtI1ASW2aCW33rTBv28jftMSYugpFvQvg/8Fnvkvc4i9wMX19rfgZD/8/0xCuOUtBhrFkHmnTWsvOErzSjgf2fNDdSpvxpEvuvR8KR5SWLWYga7IN/juDn6cKtITKaJoSo/iRRs1TkRog7Al0n2TqS4jm5mYv+oqZvCesL6GWqMWamWbZ9+Eqzhmzgv6HHtPKNzckVbvrMrGFbdL9113ZZIv4oHPkLQiZbtxiIUtDjXpj6D7h4wuzRpsVCVkbR+0UfMKNws4ZBfDhc/x70fMDy83YcCzrbjFQWJzsblr8IXgGmMieYUc+py6FuIPxwq6kkK4QoVHRiKl+tO8rmo/HcN6AZzg7y900IUf1Jomapbd+As2fJp8SJmiOglylCcmpH8dteunhvDH2ml3togGnXMOI106ssd61URQnNWffVdXL5HL9BEExbBV0mmt5sX4+Ec8eu3u58JCx6wIy+HVsH1/wHHtlhEqiSrHGr39a0ZbBk+uOBX+H0TlMpNrcnG4BnA5i81FSzXPywaf5d2Rp/i0uUUiOUUoeUUmFKqauqzSilRiulduf2ElVK9c3z2jGl1J4a0WfUStIys1gfFstrSw4w4v01dP/fP7z8+37a+HkwvntA8QcQQohqQIqJWOLiOdj/qykc4ORm62hEZZU7bS5yY/FT6PYvMhfvN86o2MI0Xe40pe//fgGaDTJVI0tCa7NOM2/CUZz0FFP2vs31JjkpL05uMOoj875+exRm9DMjZR3HmvVra98xPdxQZvSs378utwgojQ5jzLqzc8fMmrWCZGXAPy9D/XYQdOvVrzt7wO0/we+PwZq3TLP1UR+VbwsCUWJKKXvgE2AoEAVsVUot1lrvz7PZP8BirbVWSgUB84C8/8AGaa1jKyzoKig8JpnVh2JYcySGTRFxpGZk42ivCGlSl6dHtKF/K2/a+nliZyf9QYUQNYMkapbYPc+UCO9SyYuICNty84Z6LYtfp5aVASuKuHgvT0rBqA/h016w8B4zZdDSpCA1AX6eDKd3mTVW3i0s22/vfEg9byozVoQON5uCHwumwoK7TRGgE1sgPdmsaxv4rCkYU+bz5CRqexeYpK8gO74zUytvm1v4VGR7R5Oc1W4CK18xhUZunV22JFJYW3cgTGsdAaCUmguMBi4lalrr5DzbuwEyPGqhC2mZ/PfXfSzYbtbPBnq7MS6kMf1b+dCzWT3cnOVSRQhRM8n/fpbYtwh8O5rpVUIUJaAnHPjNTG20K2Rm8fZvTfXD2+fZZh2he3244QP4aQKsfh0G/7f4fc6fMGupYg+bkas5Y80aKzfvovfT2hQRqd++YlsD1GliphWufgPWvm0awV/zn5KPIBZ3jsY9YE8hiVp6Cqx6wxRxKa75vFIw4ElTrv/XB+HtlqZwUYtrTOP1Bp0K/30SFcEfOJHn6yjgqmpNSqmbgNeA+sB1eV7SwF9KKQ18rrWeWdBJlFLTgGkAAQE1Y3rfgdOJPPTDdiJiL3D/wObc3j2AxnVdbR2WEEJUCvKXvzjpFyBqKzQfZOtIRFXQpLcZPYo5WPDracnm4j2gN7QsYb81a2p7vZnKu+49U/mwKKd2mlLyCVEwYT5MWABJp+HH8cU30z6xGc7sMcVtytLnrDTsHeCa5+Dfp2H8HOsmabk6jIXofaZ3XX6bZ0DyGRjyouXvPXi8WWvX+xHIuGDWrX0xCN5qDvOnwI45kHi68P2zsyE10Wxz7pisebOegn6AV31ztda/aK3bADcCL+d5qY/WugswEnhQKdW/oJNorWdqrUO01iE+PsW0iajitNZ8v+k4oz9ZT2JqJnPu7sHTI9pIkiaEEHnIiFpxjm+E7IzLjXeFKEredWq+7a5+fdNncCHaJA4VnbjkN+J1OLoWfpkG960HZ/ertzm0zCQIrnVh4p+X39PNM2HeXbBwGtzybeGjPVu+AGevip/imVd5rgFsfyMse8ZM7/TNMzKZEg/r3jcjaU16leyYfh3Nx5AXIDkGIlaaHnRh/5hplmCmzbrUhvQkczMpLdk8ZlzId6wgGPC0GVGUEbmyiALydidvBJwqbGOt9RqlVHOllLfWOlZrfSrn+Wil1C+YqZRryjXiSizhYgbPLtzNkj1n6NfSm/fGdcLbvQTrXoUQooaQRK04R1eBnaOp6CdEceoEgruvWafW7e4rX7sQB+s/MEU1Gne3TXx5OXvATTNMH7E//23WruW15QvTTNovyBS88PC7/Fq70TDsFfjrOfj7PzD81auPn3TGFE3pPq36FuFxr29u4uyZb6ZW5ibf69+HtETLppUWeXwfk+QG3WpGx87uNQnb0TWmqItnI/O9dXYHp5wPZ3fzXGaamXb60wRToXLAU9DmhpInbElnrvzZ10xbgZZKqUDgJDAeuD3vBkqpFkB4TjGRLoATEKeUcgPstNZJOZ8PA/6vYsOvPHaeOM9DP2zndEIqT49ow739m0lxECGEKIQkasWJWG0uqqvrhaawLqXMqFpBBUXWvm1GPMp68W5NTXqb9gDr34fWI81Hdhb89R/Y9IkZiRnzZcG//70ehPPHYePHpuph/obd2741fdu6Ta2Id2I7HW8xvemiQqFxN0g4CZs/h6Bx4NveeudR6vJoW99HLdun2z1mtG/NWzDvTjMS1/9Jk2gXtj4yOdokgkfXwLG1Zj3lE0dMUlpDaa0zlVIPAX8C9sAsrfU+pdR9Oa/PAMYAdyqlMoCLwLicpM0X+EWZJN4B+EFrvcwmb8SGsrM1X607yhvLDuLr6cK8e3vStYkUzBFCiKJIolaUlHizvmbgs7aORFQlAb1MO4eEqMvVBc9HwtYvodME8Glt2/jyG/RvM0qz+GG4ZwUsexYO/g497jcjZYVd0Ctlpk+eP2FG3rwamUQPTGXL0FnQYgjUa15x78UW2lwP9o+ahKhxN1PAJDvLfF9tzd7BrHvreAvs+wVWvwnzJ4N3azPC1v4mU83z+HozDfboGog5YPZ19oSmfU2yZyd/KrTWS4Al+Z6bkefzN4A3CtgvAggu9wArscTUDB6du5MVB6MZ1s6XN8cGUdtVWlAIIURx5K9vUY6uAbSsTxMlkztNNnKT6eEFsPJ/oOwqZ9Lv4GzWnM0cAB93M1PmRrwBPe8rfl87exj7lZk+OX8KTF4CDTubypfJZ6D7h8Ufo6pz8YRWw2HvQtPQe8f3ZnSxThNbR3aZnb35XWx/k7mJsPpN07pg6dOQEgdocKhl1tMFj4PA/uAXbBI9IcogJimNu2Zt4fDZJF68oR139W6KsvX6XCGEqCLkr3BRjq42az78u9o6ElGV+HYwvzeRG83F8Zm9sGsu9HkEvPxtHV3BfNvBsFdNlcGxs6DNdcXvk8vJzbQa+HII/DDOlO3f+qXpC9ZiSPnFXJl0HAsHFsPc28CxFvR7wtYRFczO3vSZa3cjHPzNJJf120FgP/APkUbbwqpOxKcw8avNnE1M46tJ3RjQqnpXshRCCGuTRK0oEavNGh57R1tHIqoSewdo1O3yOrV//s+MuvR9zLZxFafHNLOerDTVAT18YcI8+Go4fH0dJETC0Jdt0yfOFloOAycPs55rwDOmCEhlZmdn1qm1G23rSEQ1dfhsEhO/2kxqRjbfT+1B1yZ1bB2SEEJUOVKvuTAJURAfDoEy7VGUQkAvOLsPDi6BI39C38ehVhW4UClLCff6bWHcd6bHmoOL6dNWUzjWgo5jTMXP3g/ZOhohbGpH5Dlu/XwjWsO8e3tJkiaEEKUkI2qFiVhtHmV9miiNJr0ADYvuA4+G0ONeW0dUMZoNMCNraUmm91pNMvJN09za2cPWkQhhNd9uOIaTgx3XBTXA06X42SVrj8Rw73fb8PFw5rspPQioJw2shRCitCRRK8zR1eBaD+pbsby2qDn8u5pKeakJpt+YYy1bR1Rxml9j6whsw8HZfAhRTZxNTOWFxfsAeHHxPoa19+PmLv70a+GNg/3Vo+9/7D7Noz/toLmPO7Pv7k59j3JsNi+EEDVAsYmaUqoxMBvwA7KBmVrrD/Jto4APgGuBFGCS1nq79cOtIFqbEbXA/mWbCiZqLic3s07t4jkIvr347YUQopLZEB4LwJtjg9gTlcDiXaf4bdcpfDycuamzPzd38aeNnycAP2yO5LlFe+gaUIevJnXDq5as7RZCiLKyZEQtE/iX1nq7UsoD2KaU+ltrvT/PNiOBljkfPYDPch6rptjDprS4rE8TZXHrd6bXmJQ4F0JUQeuOxFHH1ZGxXRpxa0hjnr++LSsPRjN/20lmrTvKzDURtG/oSfuGnswLjWJQax8+ndCVWk41pIiQEEKUs2KvILXWp4HTOZ8nKaUOAP5A3kRtNDBba62BTUqp2kqpBjn7Vj2yPk1YQ2Wv/CeEEIXQWrM+LJbezb2xszN9z5wd7BnRoQEjOjQgLjmNxbtOsXD7SeaFRjG6U0PeviUYxwKmRAohhCidEt3qV0o1BToDm/O95A+cyPN1VM5zVyRqSqlpwDSAgICAEoZagY6uBq8AqBNo60iEEEKIChcRe4Ezian0aeFd4Ov13J2Z3CeQyX0COZuYSn0PZ2lkLSq9jIwMoqKiSE1NtXUoogZycXGhUaNGODpaPjXc4kRNKeUOLAAe1Von5n+5gF30VU9oPROYCRASEnLV65VCdhYcWwttbzDT1oQQQogaZn2YWZ/Wp0W9Yrf19ZSiIaJqiIqKwsPDg6ZNm8qNBVGhtNbExcURFRVFYKDlA0EWzVFQSjlikrQ5WuuFBWwSBTTO83Uj4JTFUVQmp3eaSn2BA20ciBBCCGEb68NiaVSnFgF1pby+qD5SU1OpV6+eJGmiwimlqFevXolHc4tN1HIqOn4FHNBav1vIZouBO5XRE0ioiPVpWdnlMCiXuz4tsL/1jy2EEEJUclnZmo3hcfRp7i0XtKLakd9pYSul+d2zZEStDzARuEYptTPn41ql1H1KqftytlkCRABhwBfAAyWOpIQ2hsfR43//EB6TbN0DH10NPm3Bw9e6xxVCCCGqgL0nE0hMzaRPy4LXpwkhhKgYllR9XEfBa9DybqOBB60VlCWa+7gRfyGNX7af5Inhra1z0IxUiNwEXSdZ53hCCCFEFbMuZ31a7+bFr08TQghRfqpsHd36ni70a+nDLztOkm2tKZBRWyAzVfqnCSGEqLE2hMfSxs8Db3dnW4ciRI21atUqNmzYUCHnuvbaazl//nyJ9/vmm2946KGHrB+QuKRKd+K9uYs/0+fuZPPReHpZ485fxGpQdtC0T9mPJYQQQlQxqRlZbD12jok9m9g6FCHK1Uu/7WP/qfxFzMumXUNPXrihvVWOtWrVKtzd3endu7dVjlcQrTVaa5YsWVJu56gIue/Dzq7Kjj8Vqkq/o2Ht/HB3dmDh9ijrHPDoamjYBVy8rHM8IYQQogrZdvwc6ZnZ9C2kf5oQomxmz55NUFAQwcHBTJw4kd9++40ePXrQuXNnhgwZwtmzZzl27BgzZszgvffeo1OnTqxdu5aYmBjGjBlDt27d6NatG+vXrwcgJiaGoUOH0qVLF+69916aNGlCbKyZvvzuu+/SoUMHOnTowPvvvw/AsWPHaNu2LQ888ABdunThxIkTNG3a9NI++eMDCozREoXtl5yczOTJk+nYsSNBQUEsWLAAgGXLltGlSxeCg4MZPHgwAC+++CJvv/32pWN26NCBY8eOFfg+7r//fkJCQmjfvj0vvPDCpX22bt1K7969CQ4Opnv37iQlJdGvXz927tx5aZs+ffqwe/fukv44y19uFlrRH127dtXW8OTPO3W7/yzVKWmZZTvQxQStX6yj9fKXrBKXEEKIy4BQbaO/N1Xxw1p/I0vq9aUHdPNn/9DJqRk2Ob8Q5Wn//v02Pf/evXt1q1atdExMjNZa67i4OB0fH6+zs7O11lp/8cUX+vHHH9daa/3CCy/ot95669K+t912m167dq3WWuvjx4/rNm3aaK21fvDBB/X//vc/rbXWS5cu1YCOiYnRoaGhukOHDjo5OVknJSXpdu3a6e3bt+ujR49qpZTeuHHjpWM3adJEx8TEFBif1rrQGL/++mv94IMPFvp+C9vvqaee0tOnT79iu+joaN2oUSMdERFxxbnzfx/at2+vjx49WuD7yN0nMzNTDxgwQO/atUunpaXpwMBAvWXLFq211gkJCTojI0N/8803l2I4dOiQrqj/cwv6HSzq72OVnvoIcHOXRswLjeKv/WcY3cm/9Ac6vh50lqxPE0IIcRWl1AjgA8Ae+FJr/Xq+10cDLwPZQCbwqDbFuIrdtzLZEBZL54DauDlX+csDISqdFStWMHbsWLy9zYh13bp12bNnD+PGjeP06dOkp6cX2gx5+fLl7N+//9LXiYmJJCUlsW7dOn755RcARowYQZ06dQBYt24dN910E25ubgDcfPPNrF27llGjRtGkSRN69uxpUXxgGoVbEmN+he23fPly5s6de2m7OnXq8Ntvv9G/f/9L2+Seuyj538e8efOYOXMmmZmZnD59mv3796OUokGDBnTr1g0AT09PAG655RZefvll3nrrLWbNmsWkSZMsek8VrUpPfQTo3rQu/rVrsWD7ybIdKGI1OLhA4x7WCUwIIUS1oJSyBz4BRgLtgNuUUu3ybfYPEKy17gRMAb4swb6VQkJKBrtPJtC7uUx7FKI8aK2v6qX18MMP89BDD7Fnzx4+//zzQhsiZ2dns3HjRnbu3MnOnTs5efIkHh4emAGZgs9VmNzkzZL4ShKjpfsVdJ7Czu3g4EB2dvalr/OeO+/7OHr0KG+//Tb//PMPu3fv5rrrriM1NbXQ47q6ujJ06FB+/fVX5s2bx+23327Re6poVT5Rs7NT3NzFn3VHYjibWLJu31c4utokaY4u1gtOCCFEddAdCNNaR2it04G5wOi8G2itk/XlKyM3QFu6b2WxMSIOraGv9E8TolwMHjyYefPmERcXB0B8fDwJCQn4+5sZYd9+++2lbT08PEhKSrr09bBhw/j4448vfZ27vqpv377MmzcPgL/++otz584B0L9/fxYtWkRKSgoXLlzgl19+oV+/fiWODyg0xuIUtl/+93Lu3Dl69erF6tWrOXr06BXnbtq0Kdu3bwdg+/btl17PLzExETc3N7y8vDh79ixLly4FoE2bNpw6dYqtW7cCkJSURGZmJgBTp07lkUceoVu3bhaN4NlClU/UAG7q7E+2hl93lnJULTkaovdDM5n2KIQQ4ir+wIk8X0flPHcFpdRNSqmDwB+YUTWL983Zf5pSKlQpFRoTE2OVwEtifVgsrk72BDeqXeHnFqImaN++Pc899xwDBgwgODiYxx9/nBdffJFbbrmFfv36XZpyCHDDDTfwyy+/XCom8uGHHxIaGkpQUBDt2rVjxowZALzwwgv89ddfdOnShaVLl9KgQQM8PDzo0qULkyZNonv37vTo0YOpU6fSuXPnEscHFBpjcQrb7/nnn+fcuXN06NCB4OBgVq5ciY+PDzNnzuTmm28mODiYcePGATBmzBji4+Pp1KkTn332Ga1atSrwXMHBwXTu3Jn27dszZcoU+vQxFdydnJz46aefePjhhwkODmbo0KGXRuW6du2Kp6cnkydPtvg9VTRV1NBoeQoJCdGhoaFWO95Nn64nJS2LZY/2K3CIs0h75sOCu2HqCmjU1WoxCSGEMJRS27TWIbaOozSUUrcAw7XWU3O+ngh011o/XMj2/YH/aq2HlHTfXNb+G2mJa95ZRZO6rnw9uXuFnleIinLgwAHatm1r6zCsKi0tDXt7exwcHNi4cSP333//FdUMReFOnTrFwIEDOXjwYIWV9i/od7Cov4/VYkQNTFGRQ2eT2H+6FD0xjq4GZy9o2MnqcQkhhKjyooDGeb5uBJwqbGOt9RqguVLKu6T72srphItExFygj5TlF6JKiYyMpFu3bgQHB/PII4/wxRdf2DqkKmH27Nn06NGDV199tVL3X6s2ZZ1uCGrA//22j4XbT9K+YU4ftIhVsPBek4AFDjBTG+u3g/wjbhGroWlfsLOv6LCFEEJUfluBlkqpQOAkMB64YuW5UqoFEK611kqpLoATEAecL27fymB9mFmTIomaEFVLy5Yt2bFjh01jePXVV/n555+veO6WW27hueees1FExbvzzju58847bR1GsapNolbb1YnBbXz5dedJnh3ZBgd7O9j5I6QlQexhOLzMbOjqDYH9TdIWOMAkbeePQ68HbfsGhBBCVEpa60yl1EPAn5gS+7O01vuUUvflvD4DGAPcqZTKAC4C43KKixS4r03eSBHWh8VSz82J1r4etg5FCFHFPPfcc5U6KavKqk2iBnBzF3+W7TvD2iOxDGpVD8L+hjbXwpgv4XwkHF1jPiJWw76FZifnnNE36Z8mhBCiEFrrJcCSfM/NyPP5G8Ablu5bmWitWRcWS+8W3tjZlXCNtxBCiHJTrRK1ga3rU8fVkQXboxjkdhxS4qDlcPNi7QDofIf50Bpij5i1aRGrzJRHn9Y2jV0IIYSwhbDoZGKS0ujTvJ6tQxFCCJFHtUrUnBzsGBXckB+3niDVeysuyg5aDL56Q6XAp5X56H5PxQcqhBBCVBLrwmIBWZ8mhBCVTeUtc1JKN3dpRHpmNil7l0Cj7uBaORvYCSGEEJXB+rA4mtRzpXFdV1uHIoTIw93d3WrHWrRoEfv377fa8YrSu3fvUu334osv8vbbb1s5mqqt2iVqQY286FYvjbqJB6DlUFuHI4QQQlRamVnZbI6Io3dzGU0TojqriEQtKysLgA0bNpTrecpb7vuoDKrV1EcApRT3+x+Fw3C6/gAa2DogIYQQopLafTKBpLRM+sq0R1HTLH0Gzuyx7jH9OsLI1wt9+emnn6ZJkyY88MADgBlBUkqxZs0azp07R0ZGBq+88gqjR4+26HRvvvkm3333HXZ2dowcOZLXX3+dL774gpkzZ5Kenk6LFi347rvv2LlzJ4sXL2b16tW88sorLFiwAIAHH3yQmJgYXF1d+eKLL2jTpg3h4eFMmDCBrKwsRo4cybvvvktycjJaa5566imWLl2KUornn3+ecePGsWrVKl566SUaNGjAzp072b9/P+7u7iQnJ5coRlfX4kf0C9vv7Nmz3HfffURERADw2Wef0bt3b2bPns3bb7+NUoqgoCC+++47Jk2axPXXX8/YsWMBLsVa0Pu48cYbOXHiBKmpqUyfPp1p06YBsGzZMv7973+TlZWFt7c3f//9N61bt2bDhg34+PiQnZ1Nq1at2LRpE97eZfu/tdolagC9srdxStfl5xNeTG9j62iEEEKIymn9EbM+rZcUEhGi3I0fP55HH330UqI2b948li1bxmOPPYanpyexsbH07NmTUaNGofL3/M1n6dKlLFq0iM2bN+Pq6kp8fDwAN998M/fcY+ovPP/883z11Vc8/PDDjBo16ooEZfDgwcyYMYOWLVuyefNmHnjgAVasWMH06dOZPn06t912GzNmXCpsy8KFC9m5cye7du0iNjaWbt260b9/fwC2bNnC3r17CQwMLFOMxSlsv0ceeYQBAwbwyy+/kJWVRXJyMvv27ePVV19l/fr1eHt7Xzp3UfK/j1mzZlG3bl0uXrxIt27dGDNmDNnZ2dxzzz2sWbOGwMBA4uPjsbOz44477mDOnDk8+uijLF++nODg4DInaVAdE7XMdGpFrmGDWz8W7jzJI0NaFvvLLoQQQtRE68Njad/Qk7puTrYORYiKVcTIV3np3Lkz0dHRnDp1ipiYGOrUqUODBg147LHHWLNmDXZ2dpw8eZKzZ8/i5+dX5LGWL1/O5MmTL41E1a1rajLs3buX559/nvPnz5OcnMzw4cOv2jc5OZkNGzZwyy23XHouLS0NgI0bN7Jo0SIAbr/9dp544gkA1q1bx2233Ya9vT2+vr4MGDCArVu34unpSffu3a9K0soaY0EK22/FihXMnj0bAHt7e7y8vJg9ezZjx469lCzlnrso+d/Hhx9+yC+//ALAiRMnOHLkCDExMfTv3//SdrnHnTJlCqNHj+bRRx9l1qxZTJ482aL3VJzql6hFboD0JFyCR3J8bQrbI8/RtYkUFBFCCCHyupiexfbj55nUp6mtQxGixhg7dizz58/nzJkzjB8/njlz5hATE8O2bdtwdHSkadOmpKamFnscrXWBAxGTJk1i0aJFBAcH880337Bq1aqrtsnOzqZ27drs3LnT4ri11oW+5ubmZvUYC1KS/Qo7t4ODA9nZ2Ze2SU9PL/B9rFq1iuXLl7Nx40ZcXV0ZOHAgqamphR63cePG+Pr6smLFCjZv3sycOXMsek/FqXbFRDjyN9g7Edx/FLUc7Vmw/aStIxJCCCEqna3H4knPypay/EJUoPHjxzN37lzmz5/P2LFjSUhIoH79+jg6OrJy5UqOHz9u0XGGDRvGrFmzSElJAbg0tS8pKYkGDRqQkZFxRbLg4eFBUlISAJ6engQGBvLzzz8DJmHZtWsXAD179ry0hm3u3LmX9u/fvz8//fQTWVlZxMTEsGbNGrp3727VGItT2H6DBw/ms88+A0whkMTERAYPHsy8efOIi4u74txNmzZl27ZtAPz6669kZGQUeK6EhATq1KmDq6srBw8eZNOmTQD06tWL1atXc/To0SuOCzB16lTuuOMObr31Vuzt7S1+X0UpNlFTSs1SSkUrpfYW8rqXUuo3pdQupdQ+pZR1xvpK6/Cf0LQv7h61GdHBj993nSI1o/JUbxFCCCEqg/VhsTjaK7o1rWPrUERNkxIPc26F85G2jqTCtW/fnqSkJPz9/WnQoAETJkwgNDSUkJAQ5syZQ5s2lhVXGDFiBKNGjSIkJIROnTpdKmv/8ssv06NHD4YOHXrFscaPH89bb71F586dCQ8PZ86cOXz11VcEBwfTvn17fv31VwDef/993n33Xbp3787p06fx8vIC4KabbiIoKIjg4GCuueYa3nzzzWKnZ5Y0xuIUtt8HH3zAypUr6dixI127dmXfvn20b9+e5557jgEDBhAcHMzjjz8OwD333MPq1avp3r07mzdvLnQ0cMSIEWRmZhIUFMR//vMfevbsCYCPjw8zZ87k5ptvJjg4mHHjxl3aZ9SoUSQnJ1tt2iOAKmooE0Ap1R9IBmZrrTsU8Pq/AS+t9dNKKR/gEOCntU7Pv21eISEhOjQ0tPSRFyQ+Aj7sDCPegJ73seZwDHfO2sJnE7owsqPUfxRCCFtRSm3TWofYOo6qolz+RuYz8oO1eLg4MO/eXuV6HiGucnAJzL0NBr8A/R6vsNMeOHCAtm3bVtj5qqKUlBRq1aqFUoq5c+fy448/XkriRNFCQ0N57LHHWLt2baHbFPQ7WNTfx2JH1LTWa4CiSqVowEOZCZvuOdtmFnfccnH4L/OY0z+td/N6+Hg4s2inTH8UQgghch06k8SB04mMaF/0HXEhykVcmHkMX2HbOMRVtm3bRqdOnQgKCuLTTz/lnXfesXVIVcLrr7/OmDFjeO2116x6XGsUE/kYWAycAjyAcVrr7II2VEpNA6YBBAQEWOHU+Rz5C+q1gHrNAXCwt+OGoIZ8v+k4CSkZeLk6Wv+cQgghRBWzYHsUDnaK0Z0a2joUURPlJmonNkP6BXAqePqZgD179jBx4sQrnnN2dmbz5s3lcr5+/fpdWq9mKw8++CDr16+/4rnp06dbdUqhtT3zzDM888wzVj+uNRK14cBO4BqgOfC3Umqt1jox/4Za65nATDDTOqxw7svSL8CxddBt6hVP39TZn1nrj7Jk72lu614OyaEQQghRhWRmZbNw+0muaVOfeu7Otg5H1ERx4eDgApmpcHzDpZlQFaGwqn2VVceOHUtUnbE6+OSTT2wdQrkobrlZQaxR9XEysFAbYcBRoOLbTEeshqw0aDXsiqc7+HvSzMeNRTtk+qMQQgix9kgssclpjOnayNahCEukX4Bj64vfriqJC4M214G9M4SvrLDTuri4EBcXV6oLZiHKQmtNXFwcLi4uJdrPGiNqkcBgYK1SyhdoDURY4bglc+RPcHKHgN5XPK2U4sZO/rz792FOnr+If+1aFR6aEEIIUVnM3xZFXTcnBrWub+tQhCW2fgV//wce3AI+rW0dTdmlJUHyGfDtYKo/VuA6tUaNGhEVFUVMTEyFnVOIXC4uLjRqVLIbZMUmakqpH4GBgLdSKgp4AXAE0FrPAF4GvlFK7QEU8LTWOrZkoZeR1qZ/WrOB4OB01cu5idrinae4f2DzCg1NCCGEqCwSUjL4e/9Zbu8RgJND9WulWi2dzKn+uf9XGPCUbWOxhrhw81ivBdjZw9//hcRT4Fn+6yUdHR0JDAws9/MIYS2WVH28TWvdQGvtqLVupLX+Sms9IydJQ2t9Sms9TGvdUWvdQWv9ffmHnc/ZfZB4EloNL/DlgHqudAmoLdMfhRBC1GiLd58iPSubsTLtseo4ucM87l9s2zisJbeQSL0W0Pwa83nEKpuFI0RlVj1upx350zy2KHwx6k2d/Tl01pQjFkIIIUpCKTVCKXVIKRWmlLqqtJdSaoJSanfOxwalVHCe144ppfYopXYqpcq3OVoxFmyLoo2fB+0betoyDGGpC7GQEAm1A+DsnsujUVVZXDigoG4g1G8Pbj5Spl+IQlSTRO1v8AsCz8KbWl8X1BAHOyU91YQQQpSIUsoe+AQYCbQDblNKtcu32VFggNY6CLMkYGa+1wdprTvZsul3WHQyO0+cZ0yXRlWq6l2NdmqneRz4rHk8UA1G1eLCwKsxONYCOztoNsgUFMkusLOTEDVa1U/UUuJNH45Cpj3mquvmRP9WPizeeYrsbKn2I4QQwmLdgTCtdYTWOh2YC4zOu4HWeoPW+lzOl5uASje3cMH2KOztFKM7W7gWKDsbvr4WdlT8igaR41TOtMc210PDLmadWlUXF3ap3y1gpj+mxMLZvbaLSYhKquonauErQGdDy6ITNYAbO/tzOiGVzUfjKyAwIYQQ1YQ/cCLP11E5zxXmbmBpnq818JdSaptSalphOymlpimlQpVSodauSpeVrVm4PYoBrXyo72Fheegzu+H4eljztox22MqpHVCvJbh4QrtR5uvzkbaOqvS0NlMf67W4/FyzgeZRpj8KcZWqn6gd/hNc64F/l2I3HdrWFzcneykqIoQQoiQKmidY4NQMpdQgTKL2dJ6n+2itu2CmTj6olOpf0L5a65la6xCtdYiPj09ZY77C+rBYziamlayISEROf6tzRy9/LirWqe2Xr2/ajjKPVbmoyIVYSEu4MlHzbAD128nvmBAFqNqJWnYWhC2HFkNMiddi1HKyZ3gHP5bsPU1qRlYFBCiEEKIaiAIa5/m6EXAq/0ZKqSDgS2C01jou93mt9amcx2jgF8xUygo1f1sUXrUcGdy2BL3TwleAdytw9YbQWeUXnChY4mlIOg0NO5uv6zUHv45Ve51a3oqPeTUbBMc3QnpKxcckRCVWtRO1k9vgYjy0HGbxLjd28icpNZNVh6LLMTAhhBDVyFagpVIqUCnlBIwHrrhaVkoFAAuBiVrrw3med1NKeeR+DgwDKnQxTmJqBn/uO8Oo4IY4OxR/UxMwF8yRm8zf1853wKGlkCCzUSrU6Z3mMTdRA2g72qzLT7zqPkHVcClRy9fTtvk1kJUGkRsqPiYhKrGqnagd/hOUPbQYbPEuvZvXw9vdmV9k+qMQQggLaK0zgYeAP4EDwDyt9T6l1H1KqftyNvsvUA/4NF8Zfl9gnVJqF7AF+ENrvawi4/9j92nSMrMZU5Jpj8c3QFY6NB8EXSeZteA7viu3GEUBTu0AZWdG0XK1y6lhc+B328RUVnFhYOdo2g3k1aQ32DuZ6o/VWXYWhH4NF88Vv60QgIOtAyiTI39C4x5Qq47FuzjY2zEquCHfbzpOQkoGXq6O5RigEEKI6kBrvQRYku+5GXk+nwpMLWC/CCA4//MVacG2KFrUdye4kZflO4WvAHtnCOgNTq7mhui2b6HfE2BftS8dqoxTO8CnDTi5XX7Op5V5bv+v0KPQujSVV3w41G129XIVJ1cI6Fn9E7WdP8Dvj8K5YzD0JVtHI6qAqjuilngKzuyBloU3uS7MjZ0bkp6VzZK9p8shMCGEEKJyOBp7gdDj50reOy1iJTTpZS6gAUKmQNIpOFyhg4E1l9ZwcrspyZ9fu9FmimByFVzCkb/iY17Nr4HofZB0pmJjqijpKbDyf+bzHd9DZppt4xFVQtVN1GKPgItXsf3TCtLR34tmPm5S/VEIIUS1tnB7FHYKbupcVDeBfBJPQ/R+U+AhV8vh4OkPoV9ZP0hxtYQo01usYaerX2s7ykxFPVjFpj9mZ+ckas0Lfj339y1iVYWFVKE2zzA3O/r9y/xsD/xm64hEFVB1E7VmA+DJCFPStYSUUtzYyZ/NR+M5ef5iOQQnhBBC2FZ2tmbh9pP0bemDn5eFvdPg8oVy82suP2fvAF3uMlMi4yOsGqcoQG6j64JG1HzbQ93mVa9Mf2KUKRhS2IiaX5Bpt1Qd+6mlxMO696HVCBj0PNRpKpVUhUWqbqIG5g9HSaZy5DG6U0MAFu+sopWThBBCiCJsiojj5PmLJeudBuZC2dUbfDtc+XyXO00Br9CvrRekKNipHWDnYJKy/JQyza+PrjEJQFVRWGn+XHZ2ZlQtfKWZ+lnZZJehrdOatyE9CYa8aN5n18mmmXz0AauFV+mV5ftnC9nZlSLmqp2olUGTem50CajNrztl+qMQQojqZ/72KDxcHBjWztfynbKzzfq05oPMBWVeng2gzbWyvqYinNphZgw5FjIS2m406Cw4tKTg1yujuHDzWFiiBub37kI0nN1XMTFZKjMdZg6AeXeZfyMlce4YbJkJnW6H+m3Nc53vMFUua8pNj7QkeLslbPnC1pFYJnwlfNINPgiGg3/YNJQam6gB3NjZn4NnkjhwOtHWoQghhBBWk5yWydI9Z7g+qAEujhb2TgNTzOFCzJXTHvMKmWL6l1a1aXdVidYmUfMvYNpjrgadTIn7/b9WWFhlFhcGTh7gXkTT9dx1apVt+uO2b0wBu/2LYOUrJdt3xStmdHTgvy8/5+Ztku1dcyH9gjUjrZyitkJKnPleVObWBElnYP4U+O5GM5rm5A5zb4cfxsP5SJuEVKMTtes6NsDBTrFIRtWEEEJUI0v3nOZiRlbppj0CNBtY8OuBA015dSkqUn7OHYXU81c2us5PKVNUJHwlpCZUWGhlEhdmCokUtWTFyx+8W5tR3coiNRFWvwFN+0HnibD2Hdi7wLJ9T+2EPT9Dz/vNe8srZAqkJVh+rKoschOgzO/q2ndtHc3VsrNg8+fwcTdT5GXAM/DAJrhvLQz9Pzi6Gj7ubmLPTK/Q0Gp0olbP3Zn+rXxYsO2kFBURQghRbczfFkWgtxtdAizvMwqYC3+ftuDZsODXc9fXRG6Es/vLHqi42qVCIkUkamBGZLIz4FAVaZkQF1b0tMdcza8xDdczUss/Jkts+NBUaRz6f3DdO6Z/76IH4fSu4vdd/gLUqgt9H736tYBe5t9aTSgqErkJ/DpA8G0mITp/wtYRXXZyG3wxCJY+Bf5dTYI26Fkz7djeEfpMhwe3mF6S/7wEn/eDY+sqLLwanagBPDK4JWkZWdz0yXr2naoid6WEEEKIIrw+Joj/3dSxZL3TMi6aC+Tmg4rertME0wy7Jlxg2sKpHeb769O26O38Q8CjIRyoAtNQM9PM1DFLE7XMVHMzwNaSzsDGT6D9zWYqqoMzjPseXOvCj7dDckzh+4b9Yyqo9n/StJPKTykzqnZqh+mZV11lZUJUqElMB+VM/1z5qm1jAjMF8/fH4YvBkHQWxs6Cib8U3D6idmMYPwdu+wkyUuCb6+CX+4r++VuJQ7mfoZLr1Lg28+/vzaSvt3DrjI18ekdXBrTysXVYQgghRKkFersR6O1Wsp2ObzDl0wtbn5bLrR60v9GsrxnyIji7lzZM6zu6xlTS63GvrSMpvVM7zeiDg1PR29nZQdsbzPqptCRw9qiI6Ern3DHT+62wHmp5Ne0Ddo5mGm5xNw3K26rXICsDBv/n8nPu9c1F+6wRMG8i3Ln46p9Vdjb8/QLUbgLd7i78+MHjzKhb6Kyi1yRWZWf3QMYFMxJZu7H5t7nhI+j1IPh1tP75wv6BPfNNsZ3CaG2m16bEQY/7TALp4ln8sVuPgMD+sOYt8x4OLTUjrV3vsl78+dT4ETWA1n4e/PJAHwLquTHlm638tNU2CwaFEEIIm4lYaSrRNeld/LYhU0y58b3zyz+uklj9ppnCVFVH+7KzTaJWUP+0grQbbZLrI3+Va1hldqk0vwWJmpMbBPQ003BtKeYwbP/OJFp1m135WsPOMPoTM+q39Mmr2wnsmWcSlMH/NaNwhXHxgo5jTWJx8bzV30KlELnJPAb0Mo/9Hjfve/mL1j1P4ilTlfP7m+HIn3Bic+EfUVtMBc5pq2Dk65YlabmcXGHIC3D/epNoxh627vvIp8aPqOXy83Lh5/t68cCc7Ty9YA8nz13ksaGtSjZtRAghhKiqwleau95OFozENe4B9dvD1q9MI+zK8LcyK8NMsbJzhCVPgk8by5LOyiQuzCTAxa1PyxXQE9x8TBXODmPKN7ayyE3U6lqQqIEpZrPiZUiOLrpKZHn65yVwdDVTFwvScSyc3Qvr3jM9B7vfY57PSDXVDRt0MlMmixMyBbbPht0/Ve2R4MJEbgSvgMvFVGrVgX7/gr//Y6aGFla4yFJZmab9wcr/mTWb1zwPvR8pOkG2Bp/WcNdv5v+dclTsiJpSapZSKloptbeIbQYqpXYqpfYppVZbN8SK4+7swFd3hXBrSCM+XBHGv+btIj2zhP0yhBBCiKom6ay56Cxu2mMupSBkMpzZXXnW15zeDZkXTcGHOk3hp4k2K6ldapYWEsllZ2+mPx75C9JTyi+usooLMwllrdqWbZ/7exixqrwiKlrkJjj4O/SdbkrpF+aa/0DL4bDsGTi61jy39QtIOAFDX7q6F2FBGnY2I6ihsypno++y0BoiN0NAjyuf7z4NvBrD3/8teV+6vE5shS8Gwp/PmpsWD2wyiXV5J2m5lCp+inIZWTL18RtgRGEvKqVqA58Co7TW7YFbrBKZjTja2/HGmCAeH9qKhTtOMvmbLSSmlm+2LIQQQthU7gVxSdYEBY0DR7fKM80wt/hEq+Ew/kfISjc9kCpzApPfqR1mFMe7leX7tB1lChyE/1N+cZVVXLhlhURyNQg21RJt0U9Na/jrP+DuBz0fKHpbO3sY84WZGjnvTlMJcs3b0GJIyUaKQqZAzEGzTrQ6OXcMks+YJCovRxcz8nV6F+xbWPLjpsTDb9Phq6FwIQ5unQ0Tfoa6gVYJuzIpduqj1nqNUqppEZvcDizUWkfmbB9tpdhsRinFI4Nb0rB2LZ5ZsJtbPtvIW7cEkZWtOX8xg/Mp6ZxPyeBcSgYJKemcS8ng/MUMOjeuzUPXtMDRXpb+CSGEsKGks6Yxdf1iKgfmCl9hLoz9gi0/h4snBN0Cu36C4a+YKU22dGKTGUnz8DMfY76CH26FXx80Fd1sMT3z4rmSfV9O7QC/ILAvwcqUpn3Nz27nD+BVwr55BanXwvqFSeLCoOVQy7e3s4dmA8x0XK0r9md38HezhumGDyybBuziZW4MfHENfDnETIUb8lLJztlhDPz5nLnp0bRP6eIujfQUU2HTtW75HD//+rS8Ot4KGz6Gf/7PjApbMgqmNez60STSF8+ZgiQDn6nchXTKyBpr1FoBjkqpVYAH8IHWenZBGyqlpgHTAAICAqxw6vI1tmsjGni5cN932xj18fqrXlcKPF0cqe3qSC1Hez745wjrw2L56PbONPCqZYOIhRBC1Hhaw093mMX101aBezGVjHMroDUbaNlUrbxCppiqgyteheveLmXAVqC1uShsMeTyc62GmUX/y18E3/bQ/4mKjen4Rvj2erj2bTNNtDhZmWaEwZJt87J3NBe627+FQ0tKF2tert4w7BUIHm+dBCk1EZLPlmxEDaD5YNj3Cxxfb5LRipCVCctfMiOane6wfD/vFnDLLJhzi+kV5tehZOd1coVOt5k1n8mvF/9v1hrSU+DrkaYYxoCnoOeD1p/Gd2ITOHsV3GrCzg6GvgjfjzEJas/7iz5W9AH441/m96FRd7j+vZJ/n6sgayRqDkBXYDBQC9iolNqktb6qDIrWeiYwEyAkJKRKTMTt08KbPx7pR+jxeGq7OlLb1YnatRyp4+qEZy1H7O0u/yf2686TPLtwD9d9uI73x3Wiv5T5F0IIUdGUgmvfzCkffifc+WvRF2DR+82FtKXr0/JqEGwu8DZ9Ag2CoMudpY+7LOIj4EKMKXKSV59H4ew+U9zBtz20Hlkx8WhtiiVkZ5pzdxxb/F3/2ENmjZ2l69PyGvYytL4WKOOlVVa6GeVYdB/s+N6s96vfpmzHjA83jyVN1DrcbL53y1+Eu/+umFG1HbMh7giM/6Fko5pgbhI8uAVql3IgImQKbJ4BO7+Hvo+V7hiW0hoWP2RuDDTta77Hu+aan7c1k+LITdC4e+E3gJoPhsABplprp9sL7jeXfsG8vvFj82/ohg+h88SS31SqoqyRqEUBsVrrC8AFpdQaIBgo33qVFSignisB9VyL3W50J3/aN/TigTnbuOvrLTw8qAXTh7S6IpkTQgghyl1u+fAFd5ty9Te8X/i2uWXQS9uzauj/mWTv98fBu/XVhQMqQmFTrJSCUR9B7BFYcA9MXV72xMMSBxZD1FYIuRtCvzI9l3Kb/RampIVE8nLxMj2erKHNDbDjO9Pfa0Yf6PWQGXGxZBpgQeJKmag5uZnv2W+PwIHfoN2o0p3fUmnJsPI18zvU+trSHcO7ZenP79MamvSF0K+h9/TyTUTWvQd7F8DgF0y5/EPLTKXUb64zI4JDXy77qF5KvFl317GI0hVKmf8/Zg6Ade+bEfC8Di4x/38lnIDOd8CQ/zN9HGsQa/wW/Ar0U0o5KKVcgR7AASsct0pqUd+dXx/sy5gupnLkHV9uJjop1dZhCSGEKAOl1Ail1CGlVJhS6pkCXp+glNqd87FBKRVs6b7lpuNYc2d+29ew9cvCtwtfYaZ6lXZ9k72DWQPm1chMuUyIKt1xyiJyo1kLVlARDsdaZoTEsRbMvc2sbSlPWRlm+pxPW7j2LWh3oxmlSjpb9H6ndoCTh+Ul7MuLnZ1p4PtQKASNh/Xvwyc9zUVzacSFAQrqlKLQQ6cJJvlf/mK5l0Fn4ydwIdokDrZqN9FtCpw/Xr5FVA4tM+vCOoy5PHLXegQ8uBn6Pm56un0cYqYjlqki4xbzmL+QSH4NO5lkbtNnZro2mGqtP95m/r06e8DkZebGUw1L0sCy8vw/AhuB1kqpKKXU3Uqp+5RS9wForQ8Ay4DdwBbgS611oaX8a4JaTva8fUswb44NYseJc1z34To2hsfZOiwhhBCloJSyBz4BRgLtgNuUUu3ybXYUGKC1DgJeJmeav4X7lp/c8uFLn4Zj665+PSPVVJorzbTHvFzrwm1zIeMizJ1gHitS5CYz7bGwUQgvfxj3PZw/AT9PNmuRysv2b810vyEvmqIYg/9rmlKvfr3o/U7tMBetlWVKl5s33PgJTF5qRrfm3mYunkva8iAuDGo3NpX+SsrewXwf48PN97W8JMfAhg/NWr/G3cvvPMVpc4NZI1helVRjDsGCqWaa8qiPr0xI8zdy/v0xU1Xx9K7SnStyo+lpaEnz9mueB50F/7xsRvs+7m4q0Q79P7h3DTQpoBhJDVHs/wZa69u01g201o5a60Za66+01jO01jPybPOW1rqd1rqD1vr9co24Crk1pDGLHuyDh4sDE77cxCcrw8jOrhJL84QQQlzWHQjTWkdordOBucDovBtorTdorXOHajYBjSzdt1zlLx9+7viVr5/YZNZFNSvltMe86rcx5zq9C359qOJ6Ql2INeuKirtzH9ADrn/XFE4pLmkqrbQkWPU6NOlj2gQA1GueU3TlWzMFsyCZ6XBmT+mmPZa3Jr3hvrXmojlilbmIPrTU8v3jwko+7TGv1iPNdMRVb5jpiSW1ex7MGmnWbBb6MdzcXBj8QvHHK08OTtBlIhxeCgknrXvsi+fgx/EmYR7/g0nMCpLbyPmmmWZ0b+ZA2DSj4G2LErnJ3Hgo7Dx51WkK3abCrh/M6GmLwWa9X5/pplhODVZJbttUX238PFn8UF+uC2rIW38e4omfd6GrW0NDIYSo3vyBE3m+jsp5rjB3A7lXshbvq5SappQKVUqFxsTElCHcfHLLh2dlmr5ieS92w1eYu97WKiDQeqS5O753Pqz/wDrHLM6JzeaxcTGJGphiJ80Hw/5fyyeWDR+boiZDX75ytKL/U2bq5fIXC94ver8p5FEZEzUwF8t9pucUy2hsRj4suZbRuuQ91PJTynw/L0SbghIlEbEKfrnP/EzsHQv/8PI3VUvLssbMWjpPBJ0N+xdZ75hZmTB/ihlRHvd98dOclYLgcfDQVgjsDyv/Z4p6WCojFU5tv7q4T1H6P2nWx932E4yfY37PhFWKiYhiuDs78OH4TjT3ceP95Ufwr1OLfw1rbeuwhBBCWKagBSsFXqUqpQZhErXczMfifcu1MnLe8uGL7jcNYpUyhUQa9wBnd+udq9+/TKXF5S9C/XamTH55itwI9k6WJzn+Xc2oWsZFkzxZS9JZUzSk3Y3QqOuVr7n7mERn5asQufnqgitlKSRSkWo3Nr2rfptu1iAVVzjmQgykJZYtUQNo3M009l7/oRmddK9f/D7xR+HnSWbd4tS/q06vrXrNwbejuZnQ60HrHHP5C+amzA0fFD/ynFetOjDgGfh6BOxdaEb7LHF6p7nxUFD/tMK41oWbSjFyV83JiFoFUUoxfXBLxndrzEcrwpi7pYRzvIUQQthKFJD39m4j4FT+jZRSQcCXwGitdVxJ9q0QLYaY6WsHFsOat8y6nDO7oflA655HKRj9selxtOBuiCnnItCRm806GEvXQPl1MCMWMQetG8fqN8xatMH/Lfj1Xg+Cuy/8/d+rR6NO7QCX2mYKWGXXYawpehL6VfHbXqr4aIUCKYNfMM2ZV1kwbTUtyaynA7jth6qTpOVqN8qMFCda4b+KnT+akchu90DXSSXfP6CnKYxjyc8716UqrCVICkWBJFGrQEopXr6xA/1b+fDcor2sPmzFqS1CCCHKy1agpVIqUCnlBIwHFufdQCkVACwEJubrI1rsvhWq10MQNM6M7Pz5rHmurIVECuLkZqZb2jvlVFo8b/1zgBkVO7WjZC0BfHOa5J6xYt2z2COm8XfXyYUnJU5uMPAZsy4wf2PqUzvMaJqtqg2WhLO7aYa9bxFcKKZQWlyYeSzriBqYUeGuk8z3OTas8O2ys2HhvaaR8y3fmPWZVU27nGWsB34v23GitpnRz6b9YMRrpTuGUmYU89QOOLndsn0iN5mfuZt36c4pLpFErYI52tvxye2daeXrwQPfb2PfqQRbhySEEKIIWutM4CHgT0z7mXla6315KyAD/wXqAZ8qpXYqpUKL2rfC30Qupcz0p4ZdYM/PZhSnQafyOVftxjDuO1PA5OdJZipXUR9H15b8HCe3Q3ZGyaZY1QkER1czPdNa/nnJTKMc8HTR23W+E+q1zCk3n1N5MiPVrFHzt6A6XmURMtmMHu6cU/R2cWEmWfey0nqjgc+Ag4v5fhdm1Wtw6A8Y/j9oNtA6561oPq3Bp40Z/S6txNNmTaqHL9zybdmKcgSPM/9mLKlGmZ1tbkbIaJpVyBo1G/BwceTrSd246dP1TPlmK7880IeGta04T14IIYRVaa2XAEvyPZe3+vFUYKql+9qUYy2zWP+LayBwgKkMWV6a9DZFGn6bbtaFFefu5WY9kqVO5EyxKknRAjs7s3burJVG1E5sMQ2ZBz1XfJPg3HLzP00wTaVDJps4sjMr//q0vHzbm+It2742o7SFtRSICzMjWtb6HXOvD30eMcnYia1X/67s+wXWvAmd7oAe91rnnLbSdhSsfdtMUS5N8+kVL0NqAtzzT9n7j7l4mb6Me+bDsFegVu3Ct407YipMluTmiSiUjKjZiJ+XC19P7kZKWhZTvtlKYmo5N3IUQgghcnk2NBX8bqiAyoxdJ8Gje+D+DYV/TFtt+bqnvCI3mYbIrnVLtp9ve5MglbUKs9ZmzZm7r+WFH9pcZxLLVa+ZSnpVpZBIft3uhvgIOLq68G3KWvGxIL0eArf68Pd/rvz5ndkDix6ARt1NG4aqMI20KO1Gm7WUB0sx/TElHvYuMFNUfdtbJ56QKZCRYtodFCVyo3m0pAqrKJYkajbUxs+Tz+7oSlh0Mg98v52MrDJ0gBdCCCFKwsWzdE2IS6N2gLlgLOyjYScIutVUlkuJt+yY2dmm4EJpplj5dTR3/ZNOl3zfvA4tMRemA58xa9AskVtuPvksbPzUJGpuPuBZVMeHSqjtKKhVt/DkOjvLJHLWKCSSl7M7DHzafN9z+7ldiIUfbzdTecd9Dw7O1j2nLfi2N6ORpWklsWuuKbzS7W7rxdOws5kyHfpV0Tc4IjeZpt3W/rnXUJKo2Vjflt68dnNH1oXF8uzCPdJjTQghRM10ad3TD5ZtH3PQTO0qzRSr3FGGshQUyco0a83qtTRrz0oioAe0uR7Wv2/W5lWVQiJ5ObpA5zvg4BKzHiq/hCjz87T2iBpAl7vMcZe/aArKzLvL9FkbP8esyaoOlDKjakfXWH7zAkwSFToLGnUzNySsKWSK+XeXO2pWkMic9WlV7fe5kpJErRK4JaQx0we3ZP62KD78p4hKRkIIIUR15dfRTFsLnWXZlMTci8WSVHzMlZuolWWd2s7vTWXBIS+YtWclNeRFk2QkRFa9aY+5uk4CnQXbZ1/9mjUrPuZn72jK9ccegi+HwPF1MOrjqlWQxRJtR5nvb/4qoUU5ttasEwuZYv14OowBZy/YWsgoatIZOHdUColYkSRqlcSjQ1oypksj3lt+mEU7Tto6HCGEEKLidbsb4sPNKEJxTmw2a8PqBJb8PC5e4BVQ+kQtK9P082qcMzJWGt4toUvOSFzDKppg1Gtu2jts//ZyFctcl3qolUOiBtD2BpPYn91rmokH3VI+57Glhp3N7+n+ElR/DJ1lpoC2v8n68Ti5QqfbzHTM5AJaTF3qnyaFRKxFErVKQinFazd3pEdgXZ5ZuFvK9gshhKh52t0ItepYVlQkcmPZplj5dSh9if6ze8z6tu7TyjbFa/B/of9TVbeMPJiRm8STcOTPK5+PCwNnT7P+rjwoBTd+Zpq4D36hfM5ha0qZ5tfhK8w03+IkR5sKpJ0mmOqu5SFkimmJUVBrhhObwaEW+AWVz7lrIEnUKhEnBzs+vr0LtWs5cd/32zifkm7rkIQQQoiK4+hiLjIP/mGmURUm8RScjyxbZTnf9qZRdUZqyfe11siBa1245rmKK+pSHlqNBI8GV/fYigszI27luVbJu4UZTSvPFhO21m60SYwO/1n8tttnm1YPIZPLLx6f1tCkr2nNkJ2vCF7kRvDvCg5O5Xf+GkYStUrGx8OZz+7owtmENB6Zu5OsbCkuIoQQogYJmWIuNrd/V/g2lxKlMiZqOssURyipyE1mSppXFavUWB7sHUxxj7B/IP7o5efjwspv2mNN4h9iEuHiqj9mZ8G2byGwv5lWW55CJsO5YxCx4vJzaclweresT7MySdQqoc4BdXhxVHvWHI7hvb8P2zocIYQQouLUa26mAm77xlx8FiRyEzi6lq2qnW/OviWd/qh1TmW7UhQxqa663AnKzvzMADLTzIinJGplZ2dnioqELTfJUGHClpvCNCFWLMlfmLajTAn+rXlGUU9uMzc+ZH2aVUmiVknd1r0x40Ia8/HKMP7cV8T0DyGEEKK6CZkCiVFw5K+CX4/cCI1CTPW/0qobaNbTlLSgyLljkHxGRg7y8vKH1iNhx/cmSYs/CmhJ1Kyl3SjTF62wfw9gpp66+5qG6uXNwQm6TITDSyEhpwBe5CZAQeNu5X/+GkQStUpKKcVLo9sT3MiLf83bRXhMEXdRhBBCiOqk9bXg7nf1uieAtCSTXJX1zr2dPfi2K3midmKzeZSRgyuFTIaUWFPM4lJpfml6bBUBvUxRlgOFVH88H2nWsHWeWLabFyXRdZIZXd7+rfn6xCYzndjFq2LOX0NIolaJuTja89kdXXF2sOPe77aRnJZZ/E5CCCFEVWfvaKbTHfkbzh2/8rWoraCzTWn8svJtb5peW9K3LVfkRtNLyqdt2c9fnTS7Buo0Ncl1bqJWVxI1q7CzN20gDv9leu/lt+1bU7Sl66SKi6lOU2gxxJw7IxVObJFR5nIgiVol17B2LT66vTMRMck8+fMudEn+mAghhBBVVde7zMVn7rqnXJGbzHqoRlaYYuXbAS7GF11hMr/ITdC4u1k7JC6zs4Ouk+H4elO1090XXDxtHVX10W40ZFwwRVvyysow1R5bDoPajSs2ppApZhrw2ncgPblsVVhFgeR/mSqgd3Nvnh3ZlqV7zzBjdYStwxFCCCHKn1cjaDUCdnwHmXna1URuMgmWNZIA3w7m0dKCIinxpkqkjBwUrPMdYO8EUVtkNM3amvY1PQbzV388+AdciK6YIiL5tRoOno1g3Xvma/l3YXWSqFURU/sFcl1QA9768yBrjxTQDV4IIYSobkKmwIUYOPib+TorA6JCrXdB6NvOPJ7dY9n2J7aYR7kgLZibtxn5AVmfZm32jqZQyOFlpmBLrtCvTKuIFoMrPiY7ezPynZ1hEraKHtGrAYpN1JRSs5RS0UqpIlfbKqW6KaWylFJjrReeyKWU4s0xQbSs78HDP+7g3b8Ps3jXKfafSiQ1o5DyxUIIIURV1nww1A6A0K/N12f2mOlf1kqUatUBr8aWj6hFbgQ7R2jYxTrnr45CppjH8u7lVRO1HQ1piRCxynwdewSOroGQSbZr+t15Iih7uXlRThws2OYb4GNgdmEbKKXsgTcAC9qmi9Jyc3ZgxsSu3P/9Nj5aceTS2meloFGdWrTwcadFfXea+7jTzMedum5O1HZ1xKuWI472MngqhBCiisld9/TPSxBz6HLFRWuuhfFtb3midmIzNOwETq7WO391E9ALxs6CZoNsHUn102yAKWSz/1cz7TD0a7BzMMmSrXg2gNvnyQhqOSk2UdNar1FKNS1ms4eBBYA0Tyhngd5uLHu0P6kZWRyNvUBYdDJh0cmEx5jH9eFxpGdmX7Wfu7MDtV0dzUctJ7xcHWlS15Vp/ZtR29XJBu9ECCGEsEDnibDyf+aiNOmUmebl5W+94/u2N82CM9PAwbnw7TJSTVPf7tOsd+7qSCnoMMbWUVRPDs7QeoRZl5aaCDvnQNsbwL2+beNqOcS256/GLBlRK5JSyh+4CbiGYhI1pdQ0YBpAQEBAWU9do7k42tO2gSdtG1y5mDorW3Py3EWOxV3gXEo6CRczOJ+S83ExnYSUDM5fzOD06Yss23uGeaFRvHJje0Z0aGCjdyKEEJWfUmoE8AFgD3yptX493+ttgK+BLsBzWuu387x2DEgCsoBMrXVIRcVdLbj7mIa/O38wjXatPVLj2wGyM82IXYOgwrc7vROy0qV/mrCtdqNh90/wx78g9bxtioiIClPmRA14H3haa52llCpyQ631TGAmQEhIiNSZLwf2doqAeq4E1Ct+Wsbekwk8NX83932/nWs7+vHSqA74eBRxN1EIIWqgnOn9nwBDgShgq1JqsdZ6f57N4oFHgBsLOcwgrXVsuQZanYVMgb0LIA3rr4W5VPlxb9GJWuQm8yhrcYQtNb8GHN1gzzzwbmWqQYpqyxoLl0KAuTl3DMcCnyqlbrTCcUU56+Dvxa8P9eHJ4a1ZfiCaoe+tZuH2KOnVJoQQV+oOhGmtI7TW6cBcYHTeDbTW0VrrrUCGLQKs9pr0Ae/W5nNrJ0r1moODS/Hr1CI3Qb0WprKhELbiWMusTwNzA6OYQRJRtZU5UdNaB2qtm2qtmwLzgQe01ovKelxRMRzt7XhwUAuWPNKP5j7uPD5vF5O/2cqp8xdtHZoQQlQW/sCJPF9H5TxnKQ38pZTalrMEoEBKqWlKqVClVGhMjLRhuYJSMOApaNoPfNpa99h29lC/rRlRK0x2NpzYJKNponLodjc07AzB420diShnlpTn/xHYCLRWSkUppe5WSt2nlLqv/MMTFaVFfXfm3duLF25ox+aIeIa9t4bvNx0nO1tG14QQNV5Bt6xL8p9jH611F2Ak8KBSqn9BG2mtZ2qtQ7TWIT4+PqWJs3rrOBYm/W4qQVqbbwc4sxcKm1ESdwQunrNutUkhSqtpX5i2yrSXENWaJVUfb7P0YFrrSWWKRtiUvZ1icp9AhrT15ZmFu3l+0V6W7T3DZ3d0wcPF0dbhCSGErUQBeTu5NgJOWbqz1vpUzmO0UuoXzFTKNVaNUJSNbwfY8R0kR4OH79WvR240j1JIRAhRgaS5lrhK47qufH93D/53U0c2RcQx4cvNnLuQbuuwhBDCVrYCLZVSgUopJ2A8sNiSHZVSbkopj9zPgWFAEXPshE34tjePZ/cU/HrkJnD1ll5RQogKJYmaKJBSitt7BPD5xK4cPJPEuJkbiU5MLZdzJaRkcP/32/jvr3s5cjapXM5RnR04ncjzi/aw68R5W4ciRLWktc4EHgL+BA4A87TW+/IuA1BK+SmlooDHgedzlgp4Ar7AOqXULmAL8IfWeplt3oko1KVErZCCIpE569OkcIMQogJZozy/qMYGt/Xlm0ndmDo7lFs+38icqT1oVKf40v+WiktOY+JXWzgSnYRCMXvjcXo2q8vEnk0Z1t4XR3u5l1CYMwmpvPPXIeZvj0JrmLvlBP8a1pp7+zfDzk4uJiqj3VHn2XrsHL6ezvh6uuDr4UJ9T2dcHO1tHZoohtZ6CbAk33Mz8nx+BjMlMr9EILh8oxNl5loXPP3NOrX8ks7CuaOmgIMQQlQgSdREsXq38Ob7qT2YNGsLt8wwyVozH/cyHzc6MZUJX24mMj6FL+/qRoeGnswLjWLO5uM8+MN26ns4c1v3AG7rHoCfl4sV3kn1kJyWyczV4cxcG0F2NtzdJ5A7ezXljWUHeWPZQdYeieHdWzuV+HuWkJJBeGwynRrVlkSvHOw9mcCtn28kNSP7qte8ajlS38Mkb/U9nfFwdsDB3g4He4WTvR0OduZzR3uFg50dzo52DG3nS30P+XchhNX4dih4RO1Ebv80WZ8mhKhYylY9s0JCQnRoaKhNzi1KZ/+pRCZ+tRmlYPaUHrRr6FnqY508f5EJX2wiOimNr+7qRq/m9S69lpWtWX04mu82HmfV4RjslGJYO18m9mxCr+b1KK6xelWRkp7JtuPncLCzo42fB3XcnIrcPjMrm59CT/De30eITU7j+qAGPDW8zaXm5lprfg6N4oXF+3BxtOONMUEMa+9XbBxR51L4at1Rftp6gpT0LNo28OTxoa0Y0rZ+tflel9X+U4msPRLDlL6BpRrljU1OY9RH69DAnKk9yMjSnE1M5WxiKtFJaZc+P5uYRnRiKhfSs8jMyiYjS5ORnV1gITr/2rX47u7uVrlpUhGUUtu01iG2jqOqkL+RNrD8JdjwIfz7NDjk+f942bMQOgueOXHl80IIYQVF/X2URE2USHhMMnd8uZkLaZl8M6U7XQJKXho2Mi6F277YROLFDL6Z0p2uTQo/xvG4C/ywOZKfQk9wPiWDZt5ujOvWmDFdG+Ht7lyWt1Im/xw4y7bj52jt50HbBp4083bDoZgL+Kxszb5TCaw9Esu6I7FsO36O9KzLoyt+ni609vOgTQMP2vp50qaBB8283XG0V6w4GM1rSw8SFp1M96Z1+fd1benUuHaB5wmPSWb63B3sPZnIxJ5NeO66tgVOrdt7MoGZayL4Y89pFDAquCFdmtThy7URHItLIbiRF48Pa03/lt4lSti01iSlZXIxPYuU9CxS0vN+nsXFjEwupmfTo1ldmleBJGPtkRju+24bF9KzuC6oAR+M61Tszzqv9MxsJny5iT0nE5h/X286+HuVOIasbE1GVjaZ2ZrMrGzCY5KZNnsbAN9O6V6qY+aVkp7JyXMXiTp3kahzKTmPF4k6f5GT51JY/vgAaruW7QJVErWSkb+RNrBnPiy4G+5bB34dLz8/cyA4usHkP2wWmhCi+pJETVjVifgUJny5mdjkNL68K4Tezb0t3jcsOpkJX24iLTOb76b0oGMjyy4wUzOy+GP3aeZujWTrsXM42iuGtvPltu4B9GnuXWFT9S6kZfLSb/uYFxp1xfNODna08nWnXQNP2ub5SLyYwbowk5itD4/lfEoGAG0beNKvpTd9WnijgINnEv+/vTsPj6o8+zj+vTOTfYGQFZKwhUDYA42RzVdxQVQqgnXBVqxVKxZfrVar9q21tpfWqtWq1ValVqooikWki9JWRapgQ0AQaFhCWBIIJCRgFmBCkuf9YwYaNJMFZnLOSe7Pdc01M2fmJL88mZk7d85zzmFzWQ2F+2ooKq/hWKP3fRnqEpJjI9hz6AgDE6O556JspgxLabNx8jQ08viyLbz4rx0MTonh6VljyE6NwxjDim0HeGHFdj4pqiQm3M2svAyunziAPj0jAe+Wu8Vr9/DU+9vYc+gIZ/SP5wdThjBuYEKL38sYw44DdazcXsmq7ZV8WlxJZTuOEhoX4eaNm8cztPepb5kNtiWf7eGuResZlBzDlGEpPP1BEdNG9ebX7WzWjDHct3gDC1eX8MysMXx9dJ+AZSuuqOXa3+fzxZFjzLsu1+/vx5/3C/fz7IdF7Kw8TNWXfl9hrhDS4iNJ913uvGAISbGn948RbdQ6RmukBSq2wLN5MOP5/55IuL4OfpEBk+6A8+63Np9SqkvSRk0F3P7qo3zLt3/Zg5cO59yhyW3uL1NYVs235v0bEeHVG/PITj21P9C37a9h4eoSFq8t5eDhY2T0iuSq3AyuyM0gJS54++x8tvsg339jHburDvO9czK5dXIWu6rqKCyrprCshv/sraawrLrFJiUlLpxJg5JONGet/dF7rLGJ4oo6b/O2r4bt5bVMykpkVl7fDk+7W7G1gjvfXE/10WNcP6E/H22tYPO+GlLiwrl+4gBm5fWlR2TL58jzNDTy5uoSnvmgiPIaD5MGJXLnlMGM7RtP6cHDJxqzVdsr2ec7ImhqXAQTMhMY2juOqHAXUWEuIkPdRIX5boe5iApzc6S+kRvmr6ahyfDWnPH0S4ju0M/VGV5cUcxDfytk3MBevDA7l7iIUJ7/aDu/eHczXx/dhyevHN1mszZ/5U4eWLqJuZMzufvC7IBnLPviCNf+Pp+SqsM8e81Yzh/WwvmfvqS8+ig//fMm/rZhHwOTojlzQMKJhiw9PoqM+EgSY8ID/s8PbdQ6RmukBRob4OE+kHcTXPiQd1nxR/DHS+Gbb0HWBdbmU0p1SdqoqaCoqqvn23/I5/PSLwAYkBhNXv9e5A3wXtLjI09s+fm89BCzX8onwu1iwU1nBmTK29FjjSzbtI+F+SWsKq7EFSKcm53MteP6MWlQ4LayNTQ28dzy7Tz1/jZS4yJ48qoc8gb0avG5xhgqajxsKvM2bRFuF2dlJTIoOcay/b0O1Hq4e9F6PtxSweCUGG46ayDTc9IIc7ev6Tt6rJFXP93Fb5dvp7KunuTYcMprPAAkRIcxPjOB8ZkJTMhMpH9CVLt/zqLyGq743SpiI0J5a854koPYZHdEU5Ph4b8VMu/jHVw8MpUnrsw5aerob5dv55fvbWZ6Th+euDIHl5/X2SdFB5j9Uj6ThyTxwrW5QdvqW1VXz/V/yGfj3moevXwUl3+tpQMPen+uBfm7efTdzXgam7j9vCxuOmtgu18Hp0sbtY7RGmmR58+GyHiYvcR7f/kvYfkv4J6dENnTwmBKqa5KGzUVNA2NTWzY8wX5O6pYvbOK/B1VVB9tAKB3jwjO6N+Lob3jeO7DInpEhfLajeNOHPwikHYcqGPh6t28VVBKZV09A5OimT2uH5d/LZ3YiJa3GLVHSdVh7nhjHQW7DjI9pw8/mz7C7xYoOzPGUHrwyEnNc0fVeRqYv2onm/ZWk9svngmZiQxOOb0GdF3JIa558VMy4qN48+bx9IiydmzrG5q4a9F6lq7fy3Xj+/GTrw9vsRF7bnkRj763hRlj0nj8itFfec6uyjqmP/sJybHh/OmWCaf1GmyPWk8DN79SwCdFlfxk2jC+M2nASY9v2VfDj97ewJpdB5mQmcBDM0YyILFzt2Jqo9YxWiMtsmQubPs73L3Ne/+VGVBbDrd8Ym0upVSXpY2a6jRNTYat5TXk76g6cSmv8TAgMZoFN555Yj+oYPE0ePdlm79yJ+tLvyAm3M3lY9OYPaF/h7biGWNYsm4P9y/ZhAA/v2wEl41JC17wbuzjbQf4zsurGZneg1duyCMqzJqzhtR6Gpjzyho+LjrAD6cO4ZazM1ttQp/9sIjHlm1h5pg0HmvWrNUcPcbM51ZSUevhnbkTO21ap6ehkdtfX8d7m/Zx27mDuOOCwXgamnjmg208/1ExsRFufnzJMGaOTbNk6642ah2jNdIiq56DZffBXdsgshf8sh+MugqmPWF1MqVUF9VafdTzqKmACgkRslPjyE6NY/b4/hhj2HPoCIkxnXNS33C3i5lj05k5Np11JYeYv3Inr+XvZv6qXZyVlci3J/TnnCHJJ/6obmhsos7TSG19A3WeBmo93utFBaUsXb+XM/rH88SVOWT0CvxWQOU1KSuRp67OYe5ra7nl1bW8ODs3YNPxDtc3sOSzvYS6hKTYcJJjI0iKDSchOuykqYgVNR6ufzmfwrIaHvvGKK7IzWjza8+dPIimJsOv/rEVBB77xmgEuOONdRQfqOOP38nr1H3vwt0ufnPNGP7v7Y08/YH3ICGflx5iZ+VhZo5N48eXDKNXG6eAUKrbSx3hvd6/EaISoL5Wz5+mlLKMNmoqqESE9HhrmpycjJ7kXJXDjy4eyuv5u1nw713cML+AXtFhCN4tKJ6Gr558GMAdItx94RDmnJ3pdx8kFTgXjezNwzNGcu/iDfxg0Xp+fZX/fb/aa9v+Gr63YC3bymu/8pgrREiIDiM5LpykmHC27q+lqq6eedflMnlIcru/x/+el0WTgSf/uZUQ8TaD/yws58FLhzNxUPuPhhooblcIj1w+kp5RoTy/opj+CVEsuPFMS7Io5UgpvkZt30Zw+/ab7XumdXmUUt2aNmqqy0uKDee287K45ZxMlm3ax4ebKwgPDSEm3E10mJvocBcx4W5iItxEh7uJCXeT1jMy6NM01cmuzuvLoSPHeOTdzfSMDOVn04ef8hS9RQUl3P/ORmLC3bx8/RkMTIyhovYo5dUeKmo93usaD+U1R6mo9dAzKpTfXDOGMadwXsDbz8+iyRieet+7T8usvAxmj+93SrkDQUS47+KhXDSyN9mpsZ2yJVupLiOqF8T2gf2boLEe4tKgR9tb2JVSKhi0UVPdRqgrhGmj+jBtVODOZaUCa87ZmRysq+f5FcXER4Vy55QhHVq/ztPA/e9sZPHaPYwfmMBTV+ecOJpkMA5ic9wdFwwmMszF5rJqHrx0hGVH+GzO3wnRlVJtSBnunfp4uAr6jQcbvJ+VUt2TNmpKKVu596JsDh0+dmI/q8vG9GHSoKQ291vbsq+G7y1YQ/GBOm4/L4vbzsvq1Gmrc87O7LTvpZQKopThUPRPwEDGOKvTKKW6MW3UlFK2IiI8NGMEMRFuFhWUsHT9XuIi3EwZnsolo3ozaVDiSSf+NsbwZkEJP3lnE3GRoSy44Uwm6D5ZSqlTlToS8B0Ru682akop62ijppSyHbcrhPunDeOeqdl8UnSAP3++l2Ub9/HWmlJ6RIYy1de0jU7vyQNLN7Jk3V4mDUrkyatySIoNtzq+UsrJUoZ7r8Ni/3tbKaUsoI2aUsq2wtwhTM5OZnJ2Mp6GRv619QB/3VDGXzeU8UZBCcdnNt55wWDmTh6kR+hUSp2+hCxwhUHGGRCiB+NRSllHGzWllCOEu12cPyyF84elcPRYIx9trWDV9kqmjkhl3MAEq+MppboKlxsufBiSh1qdRCnVzWmjppRynIhQFxcOT+XC4alWR1FKdUV5N1mdQCmlaP0wakoppZRCRKaKyBYRKRKRe1t4PFtEVomIR0Tu6si6SimlVEvabNRE5CURKReRjX4e/6aIfO67rBSR0YGPqZRSSllDRFzAs8BFwDBglogM+9LTqoDbgMdPYV2llFLqK9qzRe1lYGorj+8AzjbGjAJ+DrwQgFxKKaWUXeQBRcaYYmNMPbAQmN78CcaYcmPMauBYR9dVSimlWtJmo2aMWYH3P4X+Hl9pjDnou/spkB6gbEoppZQdpAElze6X+pYFdF0R+a6IFIhIQUVFxSkFVUop1XUEeh+1G4B3/T2oRUgppZQDtXTeBxPodY0xLxhjco0xuUlJSe0Op5RSqmsKWKMmIpPxNmr3+HuOFiGllFIOVApkNLufDuzthHWVUkp1YwFp1ERkFDAPmG6MqQzE11RKKaVsYjWQJSIDRCQMuBpY2gnrKqWU6sZO+zxqItIXWAxca4zZevqRlFJKKfswxjSIyK3AMsAFvGSM2SQic3yP/05EUoECIA5oEpHvA8OMMdUtrWvJD6KUUspRxJjWp9mLyOvAOUAisB94AAiFE8VpHnA5sMu3SoMxJrfNbyxS0WydU5UIHDjNr9HZnJbZaXnBeZk1b/A5LXNXzNvPGKNz3tupm9ZIp+UF52XWvMHntMyaN/jayuy3PrbZqNmZiBS0pym0E6dldlpecF5mzRt8TsuseVUgOO334rS84LzMmjf4nJZZ8wbf6WQO9FEflVJKKaWUUkqdJm3UlFJKKaWUUspmnN6ovWB1gFPgtMxOywvOy6x5g89pmTWvCgSn/V6clhecl1nzBp/TMmve4DvlzI7eR00ppZRSSimluiKnb1FTSimllFJKqS5HGzWllFJKKaWUshnHNmoiMlVEtohIkYjca3WetojIThHZICLrRKTA6jwtEZGXRKRcRDY2W9ZLRP4hItt81/FWZmzOT96fisge3zivE5GLrczYnIhkiMiHIlIoIptE5HbfcjuPsb/MthxnEYkQkXwRWe/L+6BvuS3HuJW8thzf40TEJSKfichffPdtOb7dldPqI9i/RjqtPoLWyGDT+hh8WiMduo+aiLiArcAFQCmwGphljPmPpcFaISI7gVxjjG1P0ici/wPUAn80xozwLXsUqDLGPOIr+PHGmHuszHmcn7w/BWqNMY9bma0lItIb6G2MWSsiscAa4DLg29h3jP1lvhIbjrOICBBtjKkVkVDgY+B2YCY2HONW8k7FhuN7nIjcCeQCccaYaXb+nOhunFgfwf410mn1EbRGBpvWx+DTGuncLWp5QJExptgYUw8sBKZbnMnxjDErgKovLZ4OzPfdno/3Q8gW/OS1LWNMmTFmre92DVAIpGHvMfaX2ZaMV63vbqjvYrDpGLeS17ZEJB24BJjXbLEtx7eb0voYBE6rj6A1Mti0Pgaf1kjnNmppQEmz+6XY+M3hY4C/i8gaEfmu1WE6IMUYUwbeDyUg2eI87XGriHzum/Zhm034zYlIf2AM8G8cMsZfygw2HWfflIN1QDnwD2OMrcfYT16w6fgCvwZ+CDQ1W2bb8e2GnFgfwZk10qmve7t+tpzgtBqp9TF4unuNdGqjJi0ss3WHDUw0xowFLgLm+qYkqMD7LZAJ5ABlwK8sTdMCEYkB/gR83xhTbXWe9mghs23H2RjTaIzJAdKBPBEZYXGkVvnJa8vxFZFpQLkxZo3VWZRfTqyPoDWys9jys6U5p9VIrY/B1d1rpFMbtVIgo9n9dGCvRVnaxRiz13ddDryNd3qKE+z3zcM+Ph+73OI8rTLG7Pe9qZuAF7HZOPvmWP8JWGCMWexbbOsxbimz3ccZwBhzCFiOdy67rccYTs5r4/GdCFzq259oIXCuiLyKA8a3G3FcfQTH1kjHve5t/NkCOK9Gan3sPN21Rjq1UVsNZInIABEJA64GllqcyS8RifbtaIqIRANTgI2tr2UbS4HrfLevA96xMEubjr8RfGZgo3H27RT7e6DQGPNEs4dsO8b+Mtt1nEUkSUR6+m5HAucDm7HpGPvLa9fxNcbcZ4xJN8b0x/u5+4Ex5lvYdHy7KUfVR3B0jXTc696uny3gvBqp9TH4tEaCO+ApO4ExpkFEbgWWAS7gJWPMJotjtSYFeNv7nsYNvGaMec/aSF8lIq8D5wCJIlIKPAA8ArwpIjcAu4ErrEt4Mj95zxGRHLxTfXYCN1uVrwUTgWuBDb751gA/wsZjjP/Ms2w6zr2B+eI98l0I8KYx5i8isgp7jrG/vK/YdHz9sfNruFtxYH0EB9RIp9VH0BrZCbQ+Bl+3r5GOPDy/UkoppZRSSnVlTp36qJRSSimllFJdljZqSimllFJKKWUz2qgppZRSSimllM1oo6aUUkoppZRSNqONmlJKKaWUUkrZjDZqSimllFJKKWUz2qgppZRSSimllM38P/OXeG0VROcPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_val_loss_plot(history6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
